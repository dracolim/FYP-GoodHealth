{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "comments=pd.read_excel('evaluations_overall_comments.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (4.27.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from transformers) (0.13.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: requests in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Target:                      Evaluator:       Rotation Dates:  \\\n",
      "0     Eliza Chen      Dr. Ong, Andrew Ming Liang    7/1/2022-7/31/2022   \n",
      "1     Eliza Chen         Dr. Chan, Webber Pak Wo    7/1/2022-7/31/2022   \n",
      "2     Eliza Chen              Dr. Lim, Chee Hooi    7/1/2022-7/31/2022   \n",
      "3     Eliza Chen         Dr. Chang, Jason Pik Eu    8/1/2022-8/31/2022   \n",
      "4     Eliza Chen              Dr. Tan, Chee Kiat    8/1/2022-8/31/2022   \n",
      "..           ...                             ...                   ...   \n",
      "163  Rachel Yeap     Dr. Tan, Malcolm Teck Kiang    7/1/2022-7/31/2022   \n",
      "164  Rachel Yeap  Dr. Khor, Christopher Jen Lock    8/1/2022-8/31/2022   \n",
      "165  Rachel Yeap               Dr. Liou, Wei Lun    8/1/2022-8/31/2022   \n",
      "166  Rachel Yeap             Dr. Loo, Khang Ning    9/1/2022-10/2/2022   \n",
      "167  Rachel Yeap        Dr. Kwek, Andrew Boon Eu  10/3/2022-10/31/2022   \n",
      "\n",
      "                         Service:  \\\n",
      "0                             - -   \n",
      "1       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "2       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "3       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "4       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "..                            ...   \n",
      "163  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "164  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "165  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "166            SHS-IM:GEN MED-SGH   \n",
      "167       SHS-GASTRO:ADV ENDO-CGH   \n",
      "\n",
      "                                               Answer:  \\\n",
      "0    Eliza Chen is starting out and therefore as ex...   \n",
      "1    As a new senior resident to gastroenterology, ...   \n",
      "2                                           No concern   \n",
      "3    Overall I would rate Eliza Chen highly as a SR...   \n",
      "4    Eliza Chen has a quiet disposition and gives g...   \n",
      "..                                                 ...   \n",
      "163  did a week of bleeder call, good mgmt plans an...   \n",
      "164  very competent, extremely professional, and a ...   \n",
      "165  No issue. Making good progress compared to fir...   \n",
      "166  Rachel is clinically competent and I can trust...   \n",
      "167  Able to summarise key issues and suggest a rea...   \n",
      "\n",
      "                                             processed  \\\n",
      "0    Eliza Chen is starting out and therefore as ex...   \n",
      "1    As a new senior resident to gastroenterology, ...   \n",
      "2                                           No concern   \n",
      "3    Overall I would rate Eliza Chen highly as a SR...   \n",
      "4    Eliza Chen has a quiet disposition and gives g...   \n",
      "..                                                 ...   \n",
      "163  did a week of bleeder call, good mgmt plans an...   \n",
      "164  very competent, extremely professional, and a ...   \n",
      "165  No issue. Making good progress compared to fir...   \n",
      "166  Rachel is clinically competent and I can trust...   \n",
      "167  Able to summarise key issues and suggest a rea...   \n",
      "\n",
      "                         encoded  \\\n",
      "0    [input_ids, attention_mask]   \n",
      "1    [input_ids, attention_mask]   \n",
      "2    [input_ids, attention_mask]   \n",
      "3    [input_ids, attention_mask]   \n",
      "4    [input_ids, attention_mask]   \n",
      "..                           ...   \n",
      "163  [input_ids, attention_mask]   \n",
      "164  [input_ids, attention_mask]   \n",
      "165  [input_ids, attention_mask]   \n",
      "166  [input_ids, attention_mask]   \n",
      "167  [input_ids, attention_mask]   \n",
      "\n",
      "                                                output  \\\n",
      "0    {'logits': [[tensor(-2.3454, grad_fn=<UnbindBa...   \n",
      "1    {'logits': [[tensor(-2.9243, grad_fn=<UnbindBa...   \n",
      "2    {'logits': [[tensor(-0.1904, grad_fn=<UnbindBa...   \n",
      "3    {'logits': [[tensor(-2.1626, grad_fn=<UnbindBa...   \n",
      "4    {'logits': [[tensor(-0.4185, grad_fn=<UnbindBa...   \n",
      "..                                                 ...   \n",
      "163  {'logits': [[tensor(-1.2227, grad_fn=<UnbindBa...   \n",
      "164  {'logits': [[tensor(-2.4629, grad_fn=<UnbindBa...   \n",
      "165  {'logits': [[tensor(-2.6766, grad_fn=<UnbindBa...   \n",
      "166  {'logits': [[tensor(-2.3950, grad_fn=<UnbindBa...   \n",
      "167  {'logits': [[tensor(-2.2264, grad_fn=<UnbindBa...   \n",
      "\n",
      "                                     scores  \n",
      "0      [0.012829757, 0.21647434, 0.7706959]  \n",
      "1    [0.0025204902, 0.059670344, 0.9378091]  \n",
      "2       [0.17661668, 0.74489474, 0.0784886]  \n",
      "3       [0.010495567, 0.1125953, 0.8769091]  \n",
      "4       [0.18982491, 0.6115974, 0.19857769]  \n",
      "..                                      ...  \n",
      "163       [0.07528579, 0.526805, 0.3979092]  \n",
      "164    [0.002622035, 0.022788968, 0.974589]  \n",
      "165   [0.0041091316, 0.06917517, 0.9267157]  \n",
      "166   [0.010198248, 0.18377367, 0.80602807]  \n",
      "167    [0.014538733, 0.25270712, 0.7327542]  \n",
      "\n",
      "[168 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiff2/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "# labels=[]\n",
    "# mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "# with urllib.request.urlopen(mapping_link) as f:\n",
    "#     html = f.read().decode('utf-8').split(\"\\n\")\n",
    "#     csvreader = csv.reader(html, delimiter='\\t')\n",
    "# labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "comments['processed']=comments['Answer:'].apply(lambda x: preprocess(x))\n",
    "comments['encoded']=comments['processed'].apply(lambda x:tokenizer(x,return_tensors='pt'))\n",
    "comments['output']=comments['encoded'].apply(lambda x:model(**x))\n",
    "comments['scores']=comments['output'].apply(lambda x:softmax(x[0][0].detach().numpy()))\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer:</th>\n",
       "      <th>neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No concern</td>\n",
       "      <td>0.744895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Please see comments above</td>\n",
       "      <td>0.864153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>No concern</td>\n",
       "      <td>0.744895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>able to act independently in most of the clini...</td>\n",
       "      <td>0.840395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Able to work almost independently.n</td>\n",
       "      <td>0.704185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Keen to learn, follows through on tasks, techn...</td>\n",
       "      <td>0.769361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Knowledge aspect needs further improvement</td>\n",
       "      <td>0.700757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>As per earlier comments</td>\n",
       "      <td>0.849452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>We had discussed previously about Andre's 5 pe...</td>\n",
       "      <td>0.742418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Andre would need to show more dedication to le...</td>\n",
       "      <td>0.708658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>will need more guidance</td>\n",
       "      <td>0.826668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Answer:       neu\n",
       "2                                           No concern  0.744895\n",
       "5                            Please see comments above  0.864153\n",
       "18                                          No concern  0.744895\n",
       "20   able to act independently in most of the clini...  0.840395\n",
       "50                 Able to work almost independently.n  0.704185\n",
       "56   Keen to learn, follows through on tasks, techn...  0.769361\n",
       "89          Knowledge aspect needs further improvement  0.700757\n",
       "113                            As per earlier comments  0.849452\n",
       "122  We had discussed previously about Andre's 5 pe...  0.742418\n",
       "124  Andre would need to show more dedication to le...  0.708658\n",
       "160                            will need more guidance  0.826668"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEUTRAL COMMENTS: \n",
    "comments['neu']=comments['scores'].apply(lambda x: x[1])\n",
    "comments[['Answer:','neu']].loc[comments['neu']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Had a short week with her, hence limited interactions.', 0.28766068816185],\n",
       " ['Xiuhuan cares for her patients and that\\'s evident from how she greets them as people when doing the round (as opposed to patients). However she needs to apply herself more. Although she is gaining the skills and knowledge requisite of her level, she needs to remember that she is training to be a consultant and not a SR. She sometimes \"hedges\" her diagnosis and this approach will make her less effective in the long run.',\n",
       "  0.4184384047985077],\n",
       " ['enthusiastic but sometimes may lost focus', 0.37071284651756287],\n",
       " ['He needs to be more proactive in learning . He is quite passive in learning and asking senior.',\n",
       "  0.22275735437870026],\n",
       " ['I think overall whilst Andre is not a malignant person, he requires supervision to complete his tasks. With regards to his leave practices, to give him the benefit of the doubt, he \"might not have known\" and he certainly has needs for his family, however the lack of consideration on the impact of his own learning, and the impact this has on others having to cover him for weekends and ward duties is of concern.',\n",
       "  0.47441616654396057],\n",
       " ['I have not written much in this assessment. It is essentially the same with the previous one.',\n",
       "  0.32307708263397217],\n",
       " ['keen to learn. No major issue. Need to be more careful and thorough in evaluating patients with decompensated cirrhosis.',\n",
       "  0.22389227151870728]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEGATIVE COMMENTS\n",
    "comments['neg']=comments['scores'].apply(lambda x: x[0])\n",
    "comments[['Answer:','neg']].loc[comments['neg']>0.2].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['No concern', 0.07848860323429108],\n",
       " ['Eliza Chen has a quiet disposition and gives good thoughts to her management. However, because she is a bit too quiet, she does not project the impression that she have good control over her subordinates. There were knowledge gaps as we discuss cases - she is aware of them and has insight.',\n",
       "  0.19857768714427948],\n",
       " ['Please see comments above', 0.04341280087828636],\n",
       " ['No concern', 0.07848860323429108],\n",
       " ['Had a short week with her, hence limited interactions.',\n",
       "  0.032620709389448166],\n",
       " ['able to act independently in most of the clinical situation',\n",
       "  0.08608968555927277],\n",
       " ['Keen to learn, follows through on tasks, technical competencies adequate for level of training, takes effort to reflect on learning points',\n",
       "  0.18451350927352905],\n",
       " ['Xiuhuan cares for her patients and that\\'s evident from how she greets them as people when doing the round (as opposed to patients). However she needs to apply herself more. Although she is gaining the skills and knowledge requisite of her level, she needs to remember that she is training to be a consultant and not a SR. She sometimes \"hedges\" her diagnosis and this approach will make her less effective in the long run.',\n",
       "  0.08456621319055557],\n",
       " ['enthusiastic but sometimes may lost focus', 0.054053157567977905],\n",
       " ['As per earlier comments', 0.04566922411322594],\n",
       " ['He needs to be more proactive in learning . He is quite passive in learning and asking senior.',\n",
       "  0.10874912887811661],\n",
       " ['I think overall whilst Andre is not a malignant person, he requires supervision to complete his tasks. With regards to his leave practices, to give him the benefit of the doubt, he \"might not have known\" and he certainly has needs for his family, however the lack of consideration on the impact of his own learning, and the impact this has on others having to cover him for weekends and ward duties is of concern.',\n",
       "  0.04067535325884819],\n",
       " [\"We had discussed previously about Andre's 5 periods of leave during this posting which curtailed learning opportunities for the Mon am IBD list, Mon PM nutrition clinic and the Wed am nutrition round. He was given feedback to limit his leave to 1x month and to report his intention to take leave in such a manner to the faculty in a posting. He has made effort to improve his medical knowledge to a reasonable level and makes an attempt to go through the case, however it feels like he needs more time to move from a reporter and interpetator of information to offer management in a manner that reflects a specialist in training\",\n",
       "  0.13138918578624725],\n",
       " ['I have not written much in this assessment. It is essentially the same with the previous one.',\n",
       "  0.04867766052484512],\n",
       " ['keen to learn. No major issue. Need to be more careful and thorough in evaluating patients with decompensated cirrhosis.',\n",
       "  0.12460265308618546],\n",
       " ['will need more guidance', 0.04434308037161827]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NON POSITIVE COMMENTS\n",
    "comments['pos']=comments['scores'].apply(lambda x: x[2])\n",
    "comments[['Answer:','pos']].loc[comments['pos']<0.2].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Target:                      Evaluator:       Rotation Dates:  \\\n",
      "0     Eliza Chen      Dr. Ong, Andrew Ming Liang    7/1/2022-7/31/2022   \n",
      "1     Eliza Chen         Dr. Chan, Webber Pak Wo    7/1/2022-7/31/2022   \n",
      "2     Eliza Chen              Dr. Lim, Chee Hooi    7/1/2022-7/31/2022   \n",
      "3     Eliza Chen         Dr. Chang, Jason Pik Eu    8/1/2022-8/31/2022   \n",
      "4     Eliza Chen              Dr. Tan, Chee Kiat    8/1/2022-8/31/2022   \n",
      "..           ...                             ...                   ...   \n",
      "163  Rachel Yeap     Dr. Tan, Malcolm Teck Kiang    7/1/2022-7/31/2022   \n",
      "164  Rachel Yeap  Dr. Khor, Christopher Jen Lock    8/1/2022-8/31/2022   \n",
      "165  Rachel Yeap               Dr. Liou, Wei Lun    8/1/2022-8/31/2022   \n",
      "166  Rachel Yeap             Dr. Loo, Khang Ning    9/1/2022-10/2/2022   \n",
      "167  Rachel Yeap        Dr. Kwek, Andrew Boon Eu  10/3/2022-10/31/2022   \n",
      "\n",
      "                         Service:  \\\n",
      "0                             - -   \n",
      "1       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "2       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "3       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "4       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "..                            ...   \n",
      "163  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "164  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "165  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "166            SHS-IM:GEN MED-SGH   \n",
      "167       SHS-GASTRO:ADV ENDO-CGH   \n",
      "\n",
      "                                               Answer:  \\\n",
      "0    Eliza Chen is starting out and therefore as ex...   \n",
      "1    As a new senior resident to gastroenterology, ...   \n",
      "2                                           No concern   \n",
      "3    Overall I would rate Eliza Chen highly as a SR...   \n",
      "4    Eliza Chen has a quiet disposition and gives g...   \n",
      "..                                                 ...   \n",
      "163  did a week of bleeder call, good mgmt plans an...   \n",
      "164  very competent, extremely professional, and a ...   \n",
      "165  No issue. Making good progress compared to fir...   \n",
      "166  Rachel is clinically competent and I can trust...   \n",
      "167  Able to summarise key issues and suggest a rea...   \n",
      "\n",
      "                                             processed  \\\n",
      "0    Eliza Chen is starting out and therefore as ex...   \n",
      "1    As a new senior resident to gastroenterology, ...   \n",
      "2                                           No concern   \n",
      "3    Overall I would rate Eliza Chen highly as a SR...   \n",
      "4    Eliza Chen has a quiet disposition and gives g...   \n",
      "..                                                 ...   \n",
      "163  did a week of bleeder call, good mgmt plans an...   \n",
      "164  very competent, extremely professional, and a ...   \n",
      "165  No issue. Making good progress compared to fir...   \n",
      "166  Rachel is clinically competent and I can trust...   \n",
      "167  Able to summarise key issues and suggest a rea...   \n",
      "\n",
      "                         encoded  \\\n",
      "0    [input_ids, attention_mask]   \n",
      "1    [input_ids, attention_mask]   \n",
      "2    [input_ids, attention_mask]   \n",
      "3    [input_ids, attention_mask]   \n",
      "4    [input_ids, attention_mask]   \n",
      "..                           ...   \n",
      "163  [input_ids, attention_mask]   \n",
      "164  [input_ids, attention_mask]   \n",
      "165  [input_ids, attention_mask]   \n",
      "166  [input_ids, attention_mask]   \n",
      "167  [input_ids, attention_mask]   \n",
      "\n",
      "                                                output  \\\n",
      "0    {'logits': [[tensor(-2.3454, grad_fn=<UnbindBa...   \n",
      "1    {'logits': [[tensor(-2.9243, grad_fn=<UnbindBa...   \n",
      "2    {'logits': [[tensor(-0.1904, grad_fn=<UnbindBa...   \n",
      "3    {'logits': [[tensor(-2.1626, grad_fn=<UnbindBa...   \n",
      "4    {'logits': [[tensor(-0.4185, grad_fn=<UnbindBa...   \n",
      "..                                                 ...   \n",
      "163  {'logits': [[tensor(-1.2227, grad_fn=<UnbindBa...   \n",
      "164  {'logits': [[tensor(-2.4629, grad_fn=<UnbindBa...   \n",
      "165  {'logits': [[tensor(-2.6766, grad_fn=<UnbindBa...   \n",
      "166  {'logits': [[tensor(-2.3950, grad_fn=<UnbindBa...   \n",
      "167  {'logits': [[tensor(-2.2264, grad_fn=<UnbindBa...   \n",
      "\n",
      "                                     scores       neu       neg       pos  \\\n",
      "0      [0.012829757, 0.21647434, 0.7706959]  0.216474  0.012830  0.770696   \n",
      "1    [0.0025204902, 0.059670344, 0.9378091]  0.059670  0.002520  0.937809   \n",
      "2       [0.17661668, 0.74489474, 0.0784886]  0.744895  0.176617  0.078489   \n",
      "3       [0.010495567, 0.1125953, 0.8769091]  0.112595  0.010496  0.876909   \n",
      "4       [0.18982491, 0.6115974, 0.19857769]  0.611597  0.189825  0.198578   \n",
      "..                                      ...       ...       ...       ...   \n",
      "163       [0.07528579, 0.526805, 0.3979092]  0.526805  0.075286  0.397909   \n",
      "164    [0.002622035, 0.022788968, 0.974589]  0.022789  0.002622  0.974589   \n",
      "165   [0.0041091316, 0.06917517, 0.9267157]  0.069175  0.004109  0.926716   \n",
      "166   [0.010198248, 0.18377367, 0.80602807]  0.183774  0.010198  0.806028   \n",
      "167    [0.014538733, 0.25270712, 0.7327542]  0.252707  0.014539  0.732754   \n",
      "\n",
      "                                            processed2  \\\n",
      "0    Eliza Chen is starting out and therefore as ex...   \n",
      "1    As a new senior resident to gastroenterology, ...   \n",
      "2                                           No concern   \n",
      "3    Overall I would rate Eliza Chen highly as a SR...   \n",
      "4    Eliza Chen has a quiet disposition and gives g...   \n",
      "..                                                 ...   \n",
      "163  did a week of bleeder call, good mgmt plans an...   \n",
      "164  very competent, extremely professional, and a ...   \n",
      "165  No issue. Making good progress compared to fir...   \n",
      "166  Rachel is clinically competent and I can trust...   \n",
      "167  Able to summarise key issues and suggest a rea...   \n",
      "\n",
      "                        encoded2  \\\n",
      "0    [input_ids, attention_mask]   \n",
      "1    [input_ids, attention_mask]   \n",
      "2    [input_ids, attention_mask]   \n",
      "3    [input_ids, attention_mask]   \n",
      "4    [input_ids, attention_mask]   \n",
      "..                           ...   \n",
      "163  [input_ids, attention_mask]   \n",
      "164  [input_ids, attention_mask]   \n",
      "165  [input_ids, attention_mask]   \n",
      "166  [input_ids, attention_mask]   \n",
      "167  [input_ids, attention_mask]   \n",
      "\n",
      "                                               output2  \\\n",
      "0    {'logits': [[tensor(-2.7631, grad_fn=<UnbindBa...   \n",
      "1    {'logits': [[tensor(-3.0247, grad_fn=<UnbindBa...   \n",
      "2    {'logits': [[tensor(-0.3910, grad_fn=<UnbindBa...   \n",
      "3    {'logits': [[tensor(-2.3224, grad_fn=<UnbindBa...   \n",
      "4    {'logits': [[tensor(-1.3491, grad_fn=<UnbindBa...   \n",
      "..                                                 ...   \n",
      "163  {'logits': [[tensor(-1.3177, grad_fn=<UnbindBa...   \n",
      "164  {'logits': [[tensor(-3.1144, grad_fn=<UnbindBa...   \n",
      "165  {'logits': [[tensor(-3.2297, grad_fn=<UnbindBa...   \n",
      "166  {'logits': [[tensor(-2.6155, grad_fn=<UnbindBa...   \n",
      "167  {'logits': [[tensor(-2.1163, grad_fn=<UnbindBa...   \n",
      "\n",
      "                                       scores2  \n",
      "0    [0.00069301185, 0.99770457, 0.0016024436]  \n",
      "1      [0.0005676265, 0.9961947, 0.0032376717]  \n",
      "2        [0.037311796, 0.9576022, 0.005085908]  \n",
      "3      [0.0013078176, 0.9967602, 0.0019320376]  \n",
      "4      [0.0039593736, 0.9951894, 0.0008511571]  \n",
      "..                                         ...  \n",
      "163   [0.0048910673, 0.99406415, 0.0010448879]  \n",
      "164     [0.0012983002, 0.97190404, 0.02679765]  \n",
      "165    [0.0007813169, 0.99016833, 0.009050413]  \n",
      "166    [0.0007914178, 0.99747926, 0.001729251]  \n",
      "167    [0.0021298954, 0.9954731, 0.0023969747]  \n",
      "\n",
      "[168 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"trained-model\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiff2/twitter-roberta-base-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "# tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "comments['processed2']=comments['Answer:'].apply(lambda x: preprocess(x))\n",
    "comments['encoded2']=comments['processed2'].apply(lambda x:tokenizer(x,return_tensors='pt'))\n",
    "comments['output2']=comments['encoded2'].apply(lambda x:model(**x))\n",
    "comments['scores2']=comments['output2'].apply(lambda x:softmax(x[0][0].detach().numpy()))\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['scores3']=comments['scores2'].apply(lambda x:x[1])\n",
    "comments['scores3'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Target:                      Evaluator:       Rotation Dates:  \\\n",
      "0     Eliza Chen      Dr. Ong, Andrew Ming Liang    7/1/2022-7/31/2022   \n",
      "1     Eliza Chen         Dr. Chan, Webber Pak Wo    7/1/2022-7/31/2022   \n",
      "2     Eliza Chen              Dr. Lim, Chee Hooi    7/1/2022-7/31/2022   \n",
      "3     Eliza Chen         Dr. Chang, Jason Pik Eu    8/1/2022-8/31/2022   \n",
      "4     Eliza Chen              Dr. Tan, Chee Kiat    8/1/2022-8/31/2022   \n",
      "..           ...                             ...                   ...   \n",
      "163  Rachel Yeap     Dr. Tan, Malcolm Teck Kiang    7/1/2022-7/31/2022   \n",
      "164  Rachel Yeap  Dr. Khor, Christopher Jen Lock    8/1/2022-8/31/2022   \n",
      "165  Rachel Yeap               Dr. Liou, Wei Lun    8/1/2022-8/31/2022   \n",
      "166  Rachel Yeap             Dr. Loo, Khang Ning    9/1/2022-10/2/2022   \n",
      "167  Rachel Yeap        Dr. Kwek, Andrew Boon Eu  10/3/2022-10/31/2022   \n",
      "\n",
      "                         Service:  \\\n",
      "0                             - -   \n",
      "1       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "2       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "3       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "4       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "..                            ...   \n",
      "163  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "164  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "165  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "166            SHS-IM:GEN MED-SGH   \n",
      "167       SHS-GASTRO:ADV ENDO-CGH   \n",
      "\n",
      "                                               Answer:  \\\n",
      "0    Eliza Chen is starting out and therefore as ex...   \n",
      "1    As a new senior resident to gastroenterology, ...   \n",
      "2                                           No concern   \n",
      "3    Overall I would rate Eliza Chen highly as a SR...   \n",
      "4    Eliza Chen has a quiet disposition and gives g...   \n",
      "..                                                 ...   \n",
      "163  did a week of bleeder call, good mgmt plans an...   \n",
      "164  very competent, extremely professional, and a ...   \n",
      "165  No issue. Making good progress compared to fir...   \n",
      "166  Rachel is clinically competent and I can trust...   \n",
      "167  Able to summarise key issues and suggest a rea...   \n",
      "\n",
      "                                             processed  \\\n",
      "0    Eliza Chen is starting out and therefore as ex...   \n",
      "1    As a new senior resident to gastroenterology, ...   \n",
      "2                                           No concern   \n",
      "3    Overall I would rate Eliza Chen highly as a SR...   \n",
      "4    Eliza Chen has a quiet disposition and gives g...   \n",
      "..                                                 ...   \n",
      "163  did a week of bleeder call, good mgmt plans an...   \n",
      "164  very competent, extremely professional, and a ...   \n",
      "165  No issue. Making good progress compared to fir...   \n",
      "166  Rachel is clinically competent and I can trust...   \n",
      "167  Able to summarise key issues and suggest a rea...   \n",
      "\n",
      "                         encoded  \\\n",
      "0    [input_ids, attention_mask]   \n",
      "1    [input_ids, attention_mask]   \n",
      "2    [input_ids, attention_mask]   \n",
      "3    [input_ids, attention_mask]   \n",
      "4    [input_ids, attention_mask]   \n",
      "..                           ...   \n",
      "163  [input_ids, attention_mask]   \n",
      "164  [input_ids, attention_mask]   \n",
      "165  [input_ids, attention_mask]   \n",
      "166  [input_ids, attention_mask]   \n",
      "167  [input_ids, attention_mask]   \n",
      "\n",
      "                                                output  \\\n",
      "0    {'logits': [[tensor(-2.3454, grad_fn=<UnbindBa...   \n",
      "1    {'logits': [[tensor(-2.9243, grad_fn=<UnbindBa...   \n",
      "2    {'logits': [[tensor(-0.1904, grad_fn=<UnbindBa...   \n",
      "3    {'logits': [[tensor(-2.1626, grad_fn=<UnbindBa...   \n",
      "4    {'logits': [[tensor(-0.4185, grad_fn=<UnbindBa...   \n",
      "..                                                 ...   \n",
      "163  {'logits': [[tensor(-1.2227, grad_fn=<UnbindBa...   \n",
      "164  {'logits': [[tensor(-2.4629, grad_fn=<UnbindBa...   \n",
      "165  {'logits': [[tensor(-2.6766, grad_fn=<UnbindBa...   \n",
      "166  {'logits': [[tensor(-2.3950, grad_fn=<UnbindBa...   \n",
      "167  {'logits': [[tensor(-2.2264, grad_fn=<UnbindBa...   \n",
      "\n",
      "                                     scores  \\\n",
      "0      [0.012829757, 0.21647434, 0.7706959]   \n",
      "1    [0.0025204902, 0.059670344, 0.9378091]   \n",
      "2       [0.17661668, 0.74489474, 0.0784886]   \n",
      "3       [0.010495567, 0.1125953, 0.8769091]   \n",
      "4       [0.18982491, 0.6115974, 0.19857769]   \n",
      "..                                      ...   \n",
      "163       [0.07528579, 0.526805, 0.3979092]   \n",
      "164    [0.002622035, 0.022788968, 0.974589]   \n",
      "165   [0.0041091316, 0.06917517, 0.9267157]   \n",
      "166   [0.010198248, 0.18377367, 0.80602807]   \n",
      "167    [0.014538733, 0.25270712, 0.7327542]   \n",
      "\n",
      "                                            processed3  \\\n",
      "0    Eliza Chen is starting out and therefore as ex...   \n",
      "1    As a new senior resident to gastroenterology, ...   \n",
      "2                                           No concern   \n",
      "3    Overall I would rate Eliza Chen highly as a SR...   \n",
      "4    Eliza Chen has a quiet disposition and gives g...   \n",
      "..                                                 ...   \n",
      "163  did a week of bleeder call, good mgmt plans an...   \n",
      "164  very competent, extremely professional, and a ...   \n",
      "165  No issue. Making good progress compared to fir...   \n",
      "166  Rachel is clinically competent and I can trust...   \n",
      "167  Able to summarise key issues and suggest a rea...   \n",
      "\n",
      "                        encoded3  \\\n",
      "0    [input_ids, attention_mask]   \n",
      "1    [input_ids, attention_mask]   \n",
      "2    [input_ids, attention_mask]   \n",
      "3    [input_ids, attention_mask]   \n",
      "4    [input_ids, attention_mask]   \n",
      "..                           ...   \n",
      "163  [input_ids, attention_mask]   \n",
      "164  [input_ids, attention_mask]   \n",
      "165  [input_ids, attention_mask]   \n",
      "166  [input_ids, attention_mask]   \n",
      "167  [input_ids, attention_mask]   \n",
      "\n",
      "                                               output3  \\\n",
      "0    {'logits': [[tensor(-0.6942, grad_fn=<UnbindBa...   \n",
      "1    {'logits': [[tensor(-1.8881, grad_fn=<UnbindBa...   \n",
      "2    {'logits': [[tensor(-0.3084, grad_fn=<UnbindBa...   \n",
      "3    {'logits': [[tensor(-0.5836, grad_fn=<UnbindBa...   \n",
      "4    {'logits': [[tensor(0.4943, grad_fn=<UnbindBac...   \n",
      "..                                                 ...   \n",
      "163  {'logits': [[tensor(0.2993, grad_fn=<UnbindBac...   \n",
      "164  {'logits': [[tensor(-1.9801, grad_fn=<UnbindBa...   \n",
      "165  {'logits': [[tensor(-1.9249, grad_fn=<UnbindBa...   \n",
      "166  {'logits': [[tensor(-1.1620, grad_fn=<UnbindBa...   \n",
      "167  {'logits': [[tensor(0.0384, grad_fn=<UnbindBac...   \n",
      "\n",
      "                                   scores3  \n",
      "0       [0.1591694, 0.39547208, 0.4453585]  \n",
      "1     [0.013259109, 0.07446044, 0.9122805]  \n",
      "2      [0.14454493, 0.78617156, 0.0692835]  \n",
      "3     [0.15840223, 0.30918783, 0.53240997]  \n",
      "4       [0.4517273, 0.4519293, 0.09634343]  \n",
      "..                                     ...  \n",
      "163   [0.40432495, 0.46756944, 0.12810566]  \n",
      "164  [0.005084573, 0.021468803, 0.9734466]  \n",
      "165   [0.016471682, 0.11925205, 0.8642763]  \n",
      "166    [0.06608911, 0.22364852, 0.7102624]  \n",
      "167   [0.34608856, 0.40755382, 0.24635758]  \n",
      "\n",
      "[168 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"self-labelled-trained\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiff2/twitter-roberta-base-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "# tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "comments['processed3']=comments['Answer:'].apply(lambda x: preprocess(x))\n",
    "comments['encoded3']=comments['processed3'].apply(lambda x:tokenizer(x,return_tensors='pt'))\n",
    "comments['output3']=comments['encoded3'].apply(lambda x:model(**x))\n",
    "comments['scores3']=comments['output3'].apply(lambda x:softmax(x[0][0].detach().numpy()))\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer:</th>\n",
       "      <th>neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No concern</td>\n",
       "      <td>0.786172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>No concern</td>\n",
       "      <td>0.786172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>To pick up on some research projects to expand...</td>\n",
       "      <td>0.761624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>As per earlier comments</td>\n",
       "      <td>0.771054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Answer:       neu\n",
       "2                                           No concern  0.786172\n",
       "18                                          No concern  0.786172\n",
       "86   To pick up on some research projects to expand...  0.761624\n",
       "113                            As per earlier comments  0.771054"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEUTRAL COMMENTS: \n",
    "comments['neu']=comments['scores3'].apply(lambda x: x[1])\n",
    "comments[['Answer:','neu']].loc[comments['neu']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['No concern', 0.06928350031375885],\n",
       " ['Eliza Chen has a quiet disposition and gives good thoughts to her management. However, because she is a bit too quiet, she does not project the impression that she have good control over her subordinates. There were knowledge gaps as we discuss cases - she is aware of them and has insight.',\n",
       "  0.09634342789649963],\n",
       " ['Please see comments above', 0.02324148453772068],\n",
       " ['No concern', 0.06928350031375885],\n",
       " ['Had a short week with her, hence limited interactions.',\n",
       "  0.018455933779478073],\n",
       " ['able to act independently in most of the clinical situation',\n",
       "  0.0395875945687294],\n",
       " ['Able to work almost independently.n', 0.14367574453353882],\n",
       " ['Keen to learn, follows through on tasks, technical competencies adequate for level of training, takes effort to reflect on learning points',\n",
       "  0.05060121417045593],\n",
       " ['She is very introspective and seems to give a lot of thought and effort to making the clinical diagnosis or management plan. There are instances where she overthinks the diagnosis or develops an overly conservative management approach. I think this will improve as her knowledge and clinical experience grow. Rather than defensive medicine, she should focus on doing the best for the patient in front of her, and not whether the department will judge her kindly or not. This is a difficult thing to teach and a balance that is not easily learnt but by consciously asking herself the question, with time she will learn that balance.',\n",
       "  0.05822506919503212],\n",
       " ['Xiuhuan cares for her patients and that\\'s evident from how she greets them as people when doing the round (as opposed to patients). However she needs to apply herself more. Although she is gaining the skills and knowledge requisite of her level, she needs to remember that she is training to be a consultant and not a SR. She sometimes \"hedges\" her diagnosis and this approach will make her less effective in the long run.',\n",
       "  0.012866339646279812],\n",
       " ['I think Xiuhuan is a little quiet. She needs to speak up more and appear more confident. Knowledge wise, there is room for improvement.',\n",
       "  0.013304519467055798],\n",
       " ['enthusiastic but sometimes may lost focus', 0.028241774067282677],\n",
       " ['Xiuhuan has a very affable personality and down-to-earth. This enables her to interact well with the pts, families and colleagues. She demonstrates instances of \"advanced thinking\" i.e. managing pts by thinking a few steps ahead e.g. planning timing of labs and keeping in mind pt\\'s potential day of discharge. She needs to learn to think more from the big perspective e.g. when asked what is the most important lab test when we see a pre-LTx pt in the clinic, she is not able to give the correct answer (not LFT or PT). She should think from the big picture i.e. LTx is an emergency procedure and pt must be fit for GA and end-stage liver pts are often on diuretics which can perturb the UECr and serum sodium level is paramount in fitness for GA. So the answer is serum sodium. This comes from practice and she must learn to take a few steps back from a situation and reflect rather than be reflexively engrossed in the immediate situation and say things like LFT, PT, MELD-Na score etc.',\n",
       "  0.06276050209999084],\n",
       " ['performance is adequate for a first year sound in most decision making',\n",
       "  0.04163943976163864],\n",
       " ['Knowledge aspect needs further improvement', 0.011336940340697765],\n",
       " ['Responsible and clinically sound, reliable. Would do well with more reading to improve on already adequate knowledge.',\n",
       "  0.18944482505321503],\n",
       " ['Meets expectation. Continue to work on medical knowledge and clinical skills.',\n",
       "  0.11742471903562546],\n",
       " ['As per earlier comments', 0.030731428414583206],\n",
       " ['Andre could improve by showing more motivation in learning, and communicate more with his colleagues',\n",
       "  0.042734574526548386],\n",
       " ['He needs to be more proactive in learning . He is quite passive in learning and asking senior.',\n",
       "  0.011629722081124783],\n",
       " ['I think overall whilst Andre is not a malignant person, he requires supervision to complete his tasks. With regards to his leave practices, to give him the benefit of the doubt, he \"might not have known\" and he certainly has needs for his family, however the lack of consideration on the impact of his own learning, and the impact this has on others having to cover him for weekends and ward duties is of concern.',\n",
       "  0.01390756480395794],\n",
       " [\"We had discussed previously about Andre's 5 periods of leave during this posting which curtailed learning opportunities for the Mon am IBD list, Mon PM nutrition clinic and the Wed am nutrition round. He was given feedback to limit his leave to 1x month and to report his intention to take leave in such a manner to the faculty in a posting. He has made effort to improve his medical knowledge to a reasonable level and makes an attempt to go through the case, however it feels like he needs more time to move from a reporter and interpetator of information to offer management in a manner that reflects a specialist in training\",\n",
       "  0.0485348179936409],\n",
       " ['Andre would need to show more dedication to learning',\n",
       "  0.006932455115020275],\n",
       " ['I have not written much in this assessment. It is essentially the same with the previous one.',\n",
       "  0.0356614775955677],\n",
       " ['takes efforts to learn more with all complex cases manages both inpatient and outpatient case confidently',\n",
       "  0.15383091568946838],\n",
       " ['keen to learn. No major issue. Need to be more careful and thorough in evaluating patients with decompensated cirrhosis.',\n",
       "  0.020688218995928764],\n",
       " ['Very new to the SR program and needs a fair amount of guidance. Seems to be wanting to improve but comes across as being overwhelmed at times. At times also seems to rely on the MO too much for things like history, blood results etc. He needs to have a focussed plan to improve and although this will take time, it will yield benefits. For example, I suggest he pick one subject to learn about every week and he do that well by reading 3-5 review papers, not just one. Then try to practice what he has learnt rather than keep it at a knowledge level only. Thinking is difficult and requires discipline and real effort.',\n",
       "  0.04577752575278282],\n",
       " ['will need more guidance', 0.007846462540328503],\n",
       " [\"did a week of bleeder call, good mgmt plans and decision making will need to have more colonoscopes before being competent but shouldn't be a major issue\",\n",
       "  0.12810565531253815]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NON POSITIVE COMMENTS\n",
    "comments['pos']=comments['scores3'].apply(lambda x: x[2])\n",
    "comments[['Answer:','pos']].loc[comments['pos']<0.2].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (C:/Users/feryo/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|| 2/2 [00:00<00:00, 166.56it/s]\n",
      "C:\\Users\\feryo\\AppData\\Local\\Temp\\ipykernel_3996\\2059637340.py:23: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  start_logits_tensor = torch.from_numpy(np.fromstring(start_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
      "C:\\Users\\feryo\\AppData\\Local\\Temp\\ipykernel_3996\\2059637340.py:24: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  end_logits_tensor = torch.from_numpy(np.fromstring(end_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (637) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m context \u001b[39m=\u001b[39m example[\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     21\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode_plus(question, context, add_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m start_logits, end_logits \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m     23\u001b[0m start_logits_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39mfromstring(start_logits, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m     24\u001b[0m end_logits_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39mfromstring(end_logits, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:881\u001b[0m, in \u001b[0;36mDistilBertForQuestionAnswering.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    869\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    870\u001b[0m \u001b[39mstart_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[39m    Labels for position (index) of the start of the labelled span for computing the token classification loss.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[39m    are not taken into account for computing the loss.\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    879\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m--> 881\u001b[0m distilbert_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistilbert(\n\u001b[0;32m    882\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m    883\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    884\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    885\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    886\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    887\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    888\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    889\u001b[0m )\n\u001b[0;32m    890\u001b[0m hidden_states \u001b[39m=\u001b[39m distilbert_output[\u001b[39m0\u001b[39m]  \u001b[39m# (bs, max_query_len, dim)\u001b[39;00m\n\u001b[0;32m    892\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)  \u001b[39m# (bs, max_query_len, dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:578\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    575\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 578\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(input_ids)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(\n\u001b[0;32m    580\u001b[0m     x\u001b[39m=\u001b[39minputs_embeds,\n\u001b[0;32m    581\u001b[0m     attn_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    585\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m    586\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:130\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m    127\u001b[0m word_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embeddings(input_ids)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m embeddings \u001b[39m=\u001b[39m word_embeddings \u001b[39m+\u001b[39;49m position_embeddings  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    131\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    132\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (637) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import datasets\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained question answering model\n",
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load validation or test dataset\n",
    "dataset = datasets.load_dataset(\"squad\")\n",
    "\n",
    "# Loop through validation or test examples and generate predictions\n",
    "predictions = []\n",
    "for example in dataset[\"validation\"]:\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    start_logits, end_logits = model(**inputs)\n",
    "    start_logits_tensor = torch.from_numpy(np.fromstring(start_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
    "    end_logits_tensor = torch.from_numpy(np.fromstring(end_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
    "    if start_logits_tensor.numel() == 0 or end_logits_tensor.numel() == 0:\n",
    "        # If either tensor is empty, append an empty string to predictions\n",
    "        predictions.append(\"\")\n",
    "    else:\n",
    "        start_index = torch.argmax(start_logits_tensor)\n",
    "        end_index = torch.argmax(end_logits_tensor)\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_index:end_index+1]))\n",
    "        predictions.append(answer)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(dataset[\"validation\"][\"answers\"][\"text\"], predictions, average=\"macro\")\n",
    "\n",
    "print(f\"F1 score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (C:/Users/feryo/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|| 2/2 [00:00<00:00, 167.11it/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\feryo\\AppData\\Local\\Temp\\ipykernel_3996\\1568049786.py:23: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  start_logits_tensor = torch.from_numpy(np.fromstring(start_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
      "C:\\Users\\feryo\\AppData\\Local\\Temp\\ipykernel_3996\\1568049786.py:24: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  end_logits_tensor = torch.from_numpy(np.fromstring(end_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m         predictions\u001b[39m.\u001b[39mappend(answer)\n\u001b[0;32m     34\u001b[0m \u001b[39m# Calculate F1 score\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(dataset[\u001b[39m\"\u001b[39;49m\u001b[39mvalidation\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39manswers\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m], predictions, average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF1 score: \u001b[39m\u001b[39m{\u001b[39;00mf1\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import datasets\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained question answering model\n",
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load validation or test dataset\n",
    "dataset = datasets.load_dataset(\"squad\")\n",
    "\n",
    "# Loop through validation or test examples and generate predictions\n",
    "predictions = []\n",
    "for example in dataset[\"validation\"]:\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, max_length=512, return_tensors=\"pt\")\n",
    "    start_logits, end_logits = model(**inputs)\n",
    "    start_logits_tensor = torch.from_numpy(np.fromstring(start_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
    "    end_logits_tensor = torch.from_numpy(np.fromstring(end_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
    "    if start_logits_tensor.numel() == 0 or end_logits_tensor.numel() == 0:\n",
    "        # If either tensor is empty, append an empty string to predictions\n",
    "        predictions.append(\"\")\n",
    "    else:\n",
    "        start_index = torch.argmax(start_logits_tensor)\n",
    "        end_index = torch.argmax(end_logits_tensor)\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_index:end_index+1]))\n",
    "        predictions.append(answer)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(dataset[\"validation\"][\"answers\"][\"text\"], predictions, average=\"macro\")\n",
    "\n",
    "print(f\"F1 score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (C:/Users/feryo/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|| 2/2 [00:00<00:00, 167.38it/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\feryo\\AppData\\Local\\Temp\\ipykernel_3996\\1891880838.py:26: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  start_logits_tensor = torch.from_numpy(np.fromstring(start_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
      "C:\\Users\\feryo\\AppData\\Local\\Temp\\ipykernel_3996\\1891880838.py:27: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  end_logits_tensor = torch.from_numpy(np.fromstring(end_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import datasets\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained question answering model\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load validation or test dataset\n",
    "dataset = datasets.load_dataset(\"squad\")\n",
    "\n",
    "# Get validation examples\n",
    "validation_examples = dataset[\"validation\"]\n",
    "\n",
    "# Loop through validation examples and generate predictions\n",
    "predictions = []\n",
    "for example in validation_examples:\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, max_length=512, return_tensors=\"pt\")\n",
    "    start_logits, end_logits = model(**inputs)\n",
    "    start_logits_tensor = torch.from_numpy(np.fromstring(start_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
    "    end_logits_tensor = torch.from_numpy(np.fromstring(end_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
    "    if start_logits_tensor.numel() == 0 or end_logits_tensor.numel() == 0:\n",
    "            # If either tensor is empty, append an empty string to predictions\n",
    "            \n",
    "        predictions.append(\"\")\n",
    "    else:\n",
    "        start_index = torch.argmax(start_logits_tensor)\n",
    "        end_index = torch.argmax(end_logits_tensor)\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_index:end_index+1]))\n",
    "        predictions.append(answer)\n",
    "\n",
    "# Get validation answers\n",
    "validation_answers = [example[\"answers\"][\"text\"][0] for example in validation_examples]\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(validation_answers, predictions, average=\"macro\")\n",
    "\n",
    "print(f\"F1 score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'average'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m f1 \u001b[39m=\u001b[39m accuracy_score(validation_answers, predictions, average\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmacro\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(f1)\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:175\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    174\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m params \u001b[39m=\u001b[39m func_sig\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    176\u001b[0m params\u001b[39m.\u001b[39mapply_defaults()\n\u001b[0;32m    178\u001b[0m \u001b[39m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3182\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3183\u001b[0m \u001b[39m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3184\u001b[0m \u001b[39m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3185\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3186\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bind(args, kwargs)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\inspect.py:3175\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3173\u001b[0m         arguments[kwargs_param\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m kwargs\n\u001b[0;32m   3174\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3175\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   3176\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mgot an unexpected keyword argument \u001b[39m\u001b[39m{arg!r}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   3177\u001b[0m                 arg\u001b[39m=\u001b[39m\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(kwargs))))\n\u001b[0;32m   3179\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_arguments_cls(\u001b[39mself\u001b[39m, arguments)\n",
      "\u001b[1;31mTypeError\u001b[0m: got an unexpected keyword argument 'average'"
     ]
    }
   ],
   "source": [
    "f1 = accuracy_score(validation_answers, predictions, average=\"macro\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (C:/Users/feryo/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|| 2/2 [00:00<00:00, 182.27it/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\feryo\\AppData\\Local\\Temp\\ipykernel_3996\\336092189.py:32: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  start_logits_tensor = torch.from_numpy(np.fromstring(start_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
      "C:\\Users\\feryo\\AppData\\Local\\Temp\\ipykernel_3996\\336092189.py:33: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  end_logits_tensor = torch.from_numpy(np.fromstring(end_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "argmax(): Expected reduction dim to be specified for input.numel() == 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m start_logits_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39mfromstring(start_logits, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m     33\u001b[0m end_logits_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39mfromstring(end_logits, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m start_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49margmax(start_logits_tensor)\n\u001b[0;32m     35\u001b[0m end_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(end_logits_tensor)\n\u001b[0;32m     36\u001b[0m answer \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mconvert_tokens_to_string(tokenizer\u001b[39m.\u001b[39mconvert_ids_to_tokens(inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][start_index:end_index\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]))\n",
      "\u001b[1;31mIndexError\u001b[0m: argmax(): Expected reduction dim to be specified for input.numel() == 0."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import datasets\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load pre-trained question answering model\n",
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load validation or test dataset\n",
    "dataset = datasets.load_dataset(\"squad\")\n",
    "\n",
    "# Get validation or test examples\n",
    "examples = dataset[\"validation\"]  # or dataset[\"test\"]\n",
    "\n",
    "# Initialize variables for counting correct and total predictions\n",
    "num_exact_match = 0\n",
    "num_correct = 0\n",
    "total_predictions = 0\n",
    "all_ground_truths = []\n",
    "all_predictions = []\n",
    "\n",
    "# Loop through examples and generate predictions\n",
    "for example in examples:\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, max_length=512, return_tensors=\"pt\")\n",
    "    start_logits, end_logits = model(**inputs)\n",
    "    start_logits_tensor = torch.from_numpy(np.fromstring(start_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
    "    end_logits_tensor = torch.from_numpy(np.fromstring(end_logits, dtype=np.float32, sep=\" \")).unsqueeze(0)\n",
    "    start_index = torch.argmax(start_logits_tensor)\n",
    "    end_index = torch.argmax(end_logits_tensor)\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_index:end_index+1]))\n",
    "    prediction = answer.strip().lower()  # convert to lowercase and remove leading/trailing whitespace\n",
    "    ground_truths = [x[\"text\"].strip().lower() for x in example[\"answers\"]]  # convert to lowercase and remove leading/trailing whitespace\n",
    "    all_ground_truths.append(ground_truths)\n",
    "    all_predictions.append(prediction)\n",
    "    if prediction in ground_truths:\n",
    "        num_correct += 1\n",
    "    if prediction == ground_truths[0]:\n",
    "        num_exact_match += 1\n",
    "    total_predictions += 1\n",
    "\n",
    "# Calculate metrics\n",
    "exact_match = num_exact_match / total_predictions\n",
    "precision = precision_score(all_ground_truths, all_predictions, average=\"macro\")\n",
    "recall = recall_score(all_ground_truths, all_predictions, average=\"macro\")\n",
    "f1 = f1_score(all_ground_truths, all_predictions, average=\"macro\")\n",
    "\n",
    "print(f\"Exact Match: {exact_match}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
