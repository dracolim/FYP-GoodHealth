{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "comments=pd.read_excel('evaluations_overall_comments.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL STRAIGHT FROM HUGGINGFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download label mapping\n",
    "# labels=[]\n",
    "# mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "# with urllib.request.urlopen(mapping_link) as f:\n",
    "#     html = f.read().decode('utf-8').split(\"\\n\")\n",
    "#     csvreader = csv.reader(html, delimiter='\\t')\n",
    "# labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# model.save_pretrained(MODEL)\n",
    "# tokenizer.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Target:                      Evaluator:       Rotation Dates:  \\\n",
      "0     Eliza Chen      Dr. Ong, Andrew Ming Liang    7/1/2022-7/31/2022   \n",
      "1     Eliza Chen         Dr. Chan, Webber Pak Wo    7/1/2022-7/31/2022   \n",
      "2     Eliza Chen              Dr. Lim, Chee Hooi    7/1/2022-7/31/2022   \n",
      "3     Eliza Chen         Dr. Chang, Jason Pik Eu    8/1/2022-8/31/2022   \n",
      "4     Eliza Chen              Dr. Tan, Chee Kiat    8/1/2022-8/31/2022   \n",
      "..           ...                             ...                   ...   \n",
      "163  Rachel Yeap     Dr. Tan, Malcolm Teck Kiang    7/1/2022-7/31/2022   \n",
      "164  Rachel Yeap  Dr. Khor, Christopher Jen Lock    8/1/2022-8/31/2022   \n",
      "165  Rachel Yeap               Dr. Liou, Wei Lun    8/1/2022-8/31/2022   \n",
      "166  Rachel Yeap             Dr. Loo, Khang Ning    9/1/2022-10/2/2022   \n",
      "167  Rachel Yeap        Dr. Kwek, Andrew Boon Eu  10/3/2022-10/31/2022   \n",
      "\n",
      "                         Service:  \\\n",
      "0                             - -   \n",
      "1       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "2       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "3       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "4       SHS-GASTRO:BASIC ENDO-SGH   \n",
      "..                            ...   \n",
      "163  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "164  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "165  SHS-GASTRO:GEN GASTROHEP-SGH   \n",
      "166            SHS-IM:GEN MED-SGH   \n",
      "167       SHS-GASTRO:ADV ENDO-CGH   \n",
      "\n",
      "                                               Answer:  \\\n",
      "0    Eliza Chen is starting out and therefore as ex...   \n",
      "1    As a new senior resident to gastroenterology, ...   \n",
      "2                                           No concern   \n",
      "3    Overall I would rate Eliza Chen highly as a SR...   \n",
      "4    Eliza Chen has a quiet disposition and gives g...   \n",
      "..                                                 ...   \n",
      "163  did a week of bleeder call, good mgmt plans an...   \n",
      "164  very competent, extremely professional, and a ...   \n",
      "165  No issue. Making good progress compared to fir...   \n",
      "166  Rachel is clinically competent and I can trust...   \n",
      "167  Able to summarise key issues and suggest a rea...   \n",
      "\n",
      "                         encoded  \\\n",
      "0    [input_ids, attention_mask]   \n",
      "1    [input_ids, attention_mask]   \n",
      "2    [input_ids, attention_mask]   \n",
      "3    [input_ids, attention_mask]   \n",
      "4    [input_ids, attention_mask]   \n",
      "..                           ...   \n",
      "163  [input_ids, attention_mask]   \n",
      "164  [input_ids, attention_mask]   \n",
      "165  [input_ids, attention_mask]   \n",
      "166  [input_ids, attention_mask]   \n",
      "167  [input_ids, attention_mask]   \n",
      "\n",
      "                                                output  \\\n",
      "0    {'logits': [[tensor(-2.3454, grad_fn=<UnbindBa...   \n",
      "1    {'logits': [[tensor(-2.9243, grad_fn=<UnbindBa...   \n",
      "2    {'logits': [[tensor(-0.1904, grad_fn=<UnbindBa...   \n",
      "3    {'logits': [[tensor(-2.1626, grad_fn=<UnbindBa...   \n",
      "4    {'logits': [[tensor(-0.4185, grad_fn=<UnbindBa...   \n",
      "..                                                 ...   \n",
      "163  {'logits': [[tensor(-1.2227, grad_fn=<UnbindBa...   \n",
      "164  {'logits': [[tensor(-2.4629, grad_fn=<UnbindBa...   \n",
      "165  {'logits': [[tensor(-2.6766, grad_fn=<UnbindBa...   \n",
      "166  {'logits': [[tensor(-2.3950, grad_fn=<UnbindBa...   \n",
      "167  {'logits': [[tensor(-2.2264, grad_fn=<UnbindBa...   \n",
      "\n",
      "                                     scores  \n",
      "0      [0.012829757, 0.21647434, 0.7706959]  \n",
      "1    [0.0025204902, 0.059670344, 0.9378091]  \n",
      "2       [0.17661668, 0.74489474, 0.0784886]  \n",
      "3      [0.010495567, 0.11259531, 0.8769091]  \n",
      "4       [0.18982491, 0.6115974, 0.19857769]  \n",
      "..                                      ...  \n",
      "163       [0.07528579, 0.526805, 0.3979092]  \n",
      "164    [0.002622035, 0.022788968, 0.974589]  \n",
      "165   [0.0041091316, 0.06917517, 0.9267157]  \n",
      "166   [0.010198248, 0.18377367, 0.80602807]  \n",
      "167    [0.014538733, 0.25270712, 0.7327542]  \n",
      "\n",
      "[168 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "comments['encoded']=comments['Answer:'].apply(lambda x:tokenizer(x,return_tensors='pt'))\n",
    "comments['output']=comments['encoded'].apply(lambda x:model(**x))\n",
    "comments['scores']=comments['output'].apply(lambda x:softmax(x[0][0].detach().numpy()))\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEUTRAL COMMENTS: \n",
    "comments['neu']=comments['scores'].apply(lambda x: x[1])\n",
    "# comments[['Answer:','neu']].loc[comments['neu']>0.7]\n",
    "# NEGATIVE COMMENTS\n",
    "comments['neg']=comments['scores'].apply(lambda x: x[0])\n",
    "# comments[['Answer:','neg']].loc[comments['neg']>0.2].values.tolist()\n",
    "# NON POSITIVE COMMENTS\n",
    "comments['pos']=comments['scores'].apply(lambda x: x[2])\n",
    "# comments[['Answer:','pos']].loc[comments['pos']<0.2].values.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL TRAINED ON IMDB DATASET (bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"trained-model\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "# tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "comments['processed2']=comments['Answer:'].apply(lambda x: preprocess(x))\n",
    "comments['encoded2']=comments['processed2'].apply(lambda x:tokenizer(x,return_tensors='pt'))\n",
    "comments['output2']=comments['encoded2'].apply(lambda x:model(**x))\n",
    "comments['scores2']=comments['output2'].apply(lambda x:softmax(x[0][0].detach().numpy()))\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['scores3']=comments['scores2'].apply(lambda x:x[1])\n",
    "comments['scores3'].values.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL TRAINED ON SELF LABELLED DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"csv_batch16\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "# tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "comments['encoded3']=comments['Answer:'].apply(lambda x:tokenizer(x,return_tensors='pt'))\n",
    "comments['output3']=comments['encoded3'].apply(lambda x:model(**x))\n",
    "comments['c16']=comments['output3'].apply(lambda x:softmax(x[0][0].detach().numpy()))\n",
    "# NEUTRAL COMMENTS: \n",
    "comments['neu c16']=comments['c16'].apply(lambda x:x[1])\n",
    "comments['neg c16']=comments['c16'].apply(lambda x:x[0])\n",
    "comments['pos c16']=comments['c16'].apply(lambda x: x[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"finetuned-model\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "# tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "comments['encoded10']=comments['Answer:'].apply(lambda x:tokenizer(x,return_tensors='pt'))\n",
    "comments['output10']=comments['encoded10'].apply(lambda x:model(**x))\n",
    "comments['c10']=comments['output10'].apply(lambda x:softmax(x[0][0].detach().numpy()))\n",
    "# NEUTRAL COMMENTS: \n",
    "comments['neu c10']=comments['c10'].apply(lambda x:x[1])\n",
    "comments['neg c10']=comments['c10'].apply(lambda x:x[0])\n",
    "comments['pos c10']=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pos       neu       neg  pos c10   neu c10   neg c10\n",
      "0    0.770696  0.216474  0.012830        2  0.395472  0.159170\n",
      "1    0.937809  0.059670  0.002520        2  0.074460  0.013259\n",
      "2    0.078489  0.744895  0.176617        2  0.786172  0.144544\n",
      "3    0.876909  0.112595  0.010496        2  0.309187  0.158402\n",
      "4    0.198578  0.611597  0.189825        2  0.451928  0.451729\n",
      "..        ...       ...       ...      ...       ...       ...\n",
      "163  0.397909  0.526805  0.075286        2  0.467569  0.404326\n",
      "164  0.974589  0.022789  0.002622        2  0.021468  0.005085\n",
      "165  0.926716  0.069175  0.004109        2  0.119251  0.016472\n",
      "166  0.806028  0.183774  0.010198        2  0.223648  0.066089\n",
      "167  0.732754  0.252707  0.014539        2  0.407553  0.346090\n",
      "\n",
      "[168 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(comments[['pos','neu','neg','pos c10','neu c10','neg c10']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"csv_batch10\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "# tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "comments['encoded10']=comments['Answer:'].apply(lambda x:tokenizer(x,return_tensors='pt'))\n",
    "comments['output10']=comments['encoded10'].apply(lambda x:model(**x))\n",
    "comments['c10']=comments['output10'].apply(lambda x:softmax(x[0][0].detach().numpy()))\n",
    "# NEUTRAL COMMENTS: \n",
    "comments['neu c10']=comments['c10'].apply(lambda x:x[1])\n",
    "comments['neg c10']=comments['c10'].apply(lambda x:x[0])\n",
    "comments['pos c10']=comments['c10'].apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"csv_batch8\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "# tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "comments['encoded4']=comments['Answer:'].apply(lambda x:tokenizer(x,return_tensors='pt'))\n",
    "comments['output4']=comments['encoded4'].apply(lambda x:model(**x))\n",
    "comments['c8']=comments['output4'].apply(lambda x:softmax(x[0][0].detach().numpy()))\n",
    "# NEUTRAL COMMENTS: \n",
    "comments['neu c8']=comments['c8'].apply(lambda x:x[1])\n",
    "comments['neg c8']=comments['c8'].apply(lambda x:x[0])\n",
    "comments['pos c8']=comments['c8'].apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# model.save_pretrained(MODEL)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# tokenizer.save_pretrained(MODEL)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m comments[\u001b[39m'\u001b[39m\u001b[39mencoded5\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mcomments[\u001b[39m'\u001b[39m\u001b[39mAnswer:\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x:tokenizer(x,return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m comments[\u001b[39m'\u001b[39m\u001b[39moutput5\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mcomments[\u001b[39m'\u001b[39;49m\u001b[39mencoded5\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x:model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mx))\n\u001b[0;32m     10\u001b[0m comments[\u001b[39m'\u001b[39m\u001b[39mx16\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mcomments[\u001b[39m'\u001b[39m\u001b[39moutput5\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x:softmax(x[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()))\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(comments)\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# model.save_pretrained(MODEL)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# tokenizer.save_pretrained(MODEL)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m comments[\u001b[39m'\u001b[39m\u001b[39mencoded5\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mcomments[\u001b[39m'\u001b[39m\u001b[39mAnswer:\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x:tokenizer(x,return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m comments[\u001b[39m'\u001b[39m\u001b[39moutput5\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mcomments[\u001b[39m'\u001b[39m\u001b[39mencoded5\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x:model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mx))\n\u001b[0;32m     10\u001b[0m comments[\u001b[39m'\u001b[39m\u001b[39mx16\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mcomments[\u001b[39m'\u001b[39m\u001b[39moutput5\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x:softmax(x[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()))\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(comments)\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1212\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1205\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1212\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[0;32m   1213\u001b[0m     input_ids,\n\u001b[0;32m   1214\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1215\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1216\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1217\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1218\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1219\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1220\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1221\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1222\u001b[0m )\n\u001b[0;32m   1223\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1224\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:852\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    843\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    845\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m    846\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m    847\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    850\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    851\u001b[0m )\n\u001b[1;32m--> 852\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    853\u001b[0m     embedding_output,\n\u001b[0;32m    854\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    855\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    856\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    857\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    858\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    859\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    860\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    861\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    862\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    863\u001b[0m )\n\u001b[0;32m    864\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    865\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:527\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    518\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    520\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    525\u001b[0m     )\n\u001b[0;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 527\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    528\u001b[0m         hidden_states,\n\u001b[0;32m    529\u001b[0m         attention_mask,\n\u001b[0;32m    530\u001b[0m         layer_head_mask,\n\u001b[0;32m    531\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    532\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    533\u001b[0m         past_key_value,\n\u001b[0;32m    534\u001b[0m         output_attentions,\n\u001b[0;32m    535\u001b[0m     )\n\u001b[0;32m    537\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    538\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:411\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    400\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    401\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    408\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    409\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 411\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    412\u001b[0m         hidden_states,\n\u001b[0;32m    413\u001b[0m         attention_mask,\n\u001b[0;32m    414\u001b[0m         head_mask,\n\u001b[0;32m    415\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    416\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    417\u001b[0m     )\n\u001b[0;32m    418\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    420\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:338\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    330\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    337\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 338\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    339\u001b[0m         hidden_states,\n\u001b[0;32m    340\u001b[0m         attention_mask,\n\u001b[0;32m    341\u001b[0m         head_mask,\n\u001b[0;32m    342\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    343\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    344\u001b[0m         past_key_value,\n\u001b[0;32m    345\u001b[0m         output_attentions,\n\u001b[0;32m    346\u001b[0m     )\n\u001b[0;32m    347\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[0;32m    348\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\feryo\\OneDrive\\Documents\\GitHub\\FYP-GoodHealth\\.venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:234\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    231\u001b[0m     past_key_value \u001b[39m=\u001b[39m (key_layer, value_layer)\n\u001b[0;32m    233\u001b[0m \u001b[39m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m attention_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(query_layer, key_layer\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m))\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelative_key\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelative_key_query\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    237\u001b[0m     query_length, key_length \u001b[39m=\u001b[39m query_layer\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], key_layer\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MODEL = f\"excel_batch16\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "# tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "comments['encoded5']=comments['Answer:'].apply(lambda x:tokenizer(x,return_tensors='pt'))\n",
    "comments['output5']=comments['encoded5'].apply(lambda x:model(**x))\n",
    "comments['x16']=comments['output5'].apply(lambda x:softmax(x[0][0].detach().numpy()))\n",
    "print(comments)\n",
    "\n",
    "comments['neu x16']=comments['x16'].apply(lambda x:x[1])\n",
    "comments['neg x16']=comments['x16'].apply(lambda x:x[0])\n",
    "comments['pos x16']=comments['x16'].apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_excel('comments_with_score2.xlsx')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b9cd609fe250df32380b10f589404d8f31c7e924815d1cf5d2fd9dff4822a00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
