{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sentiment Analysis (Evaluations)</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DATA EXPLORATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. PRE-TRAINED MODELS: COMPARING PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments=pd.read_excel('comments.xlsx')\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install vaderSentimentlibrary\n",
    "!pip install vaderSentiment\n",
    "\n",
    "#import the library\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#calculate the negative, positive, neutral and compound scores, plus verbal evaluation\n",
    "def sentiment_vader(sentence):\n",
    "\n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    negative = sentiment_dict['neg']\n",
    "    neutral = sentiment_dict['neu']\n",
    "    positive = sentiment_dict['pos']\n",
    "    compound = sentiment_dict['compound']\n",
    "\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        overall_sentiment = \"Positive\"\n",
    "\n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        overall_sentiment = \"Negative\"\n",
    "\n",
    "    else :\n",
    "        overall_sentiment = \"Neutral\"\n",
    "  \n",
    "    return negative, neutral, positive, compound, overall_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=comments.apply(lambda x: sentiment_vader(x['Comments']),axis=1)\n",
    "a.iloc[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# install textblob\n",
    "!pip install textblob\n",
    "\n",
    "# import it\n",
    "from textblob import TextBlob\n",
    "\n",
    "#call the classifier\n",
    "def sentiment_texblob(row):\n",
    "  \n",
    "    classifier = TextBlob(row)\n",
    "    polarity = classifier.sentiment.polarity\n",
    "    subjectivity = classifier.sentiment.subjectivity\n",
    "    \n",
    "    return polarity,subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=comments.apply(lambda x: sentiment_texblob(x['Comments']),axis=1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install happytransformer\n",
    "from happytransformer import HappyTextClassification\n",
    "happy_tc=HappyTextClassification(model_type='DISTILBERT',model_name='distilbert-base-uncased-finetuned-sst-2-english',num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=comments.apply(lambda x: happy_tc.classify_text(x['Comments']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "comments=pd.read_excel('comments.xlsx')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "n_gram_range = (1, 1)\n",
    "stop_words = \"english\"\n",
    "\n",
    "sentences=comments['Comments'].values.tolist()\n",
    "# Extract candidate words/phrases\n",
    "count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit(sentences)\n",
    "candidates = count.get_feature_names()\n",
    "\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "doc_embedding = model.encode([doc])\n",
    "candidate_embeddings = model.encode(candidates)\n",
    "doc_embedding\n",
    "comments['Doc_Embed']=comments.apply(lambda x: model.encode([x['Comments']]),axis=1)\n",
    "comments['Distance']=comments.apply(lambda x:cosine_similarity(x['Doc_Embed'],candidate_embeddings),axis=1)\n",
    "top_n = 5\n",
    "\n",
    "comments['Keywords']=comments['Distance'].apply(lambda x: [candidates[index] for index in x.argsort()[0][-top_n:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['Keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# QUESTION ANSWERING: Very very bad\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment analysis and question answering models\n",
    "sa_model = pipeline(\"sentiment-analysis\")\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "\n",
    "# Review to analyze\n",
    "\n",
    "comments['Sentiment']=comments['Comments'].apply(lambda x: sa_model(x)[0]['label'])\n",
    "\n",
    "\n",
    "def get_q_list(row):\n",
    "    q_list=[]\n",
    "    for i in row['Keywords']:\n",
    "        q_list.append(f'Why was it {i}?')\n",
    "    return q_list\n",
    "comments['Questions']=comments.apply(get_q_list,axis=1)\n",
    "\n",
    "def get_a_list(row):\n",
    "    a_list=[]\n",
    "    for i in row['Questions']:\n",
    "        a_list.append(qa_model(question=i, context=row['Comments'])['answer'])\n",
    "    return a_list\n",
    "comments['Answers']=comments.apply(get_a_list,axis=1)\n",
    "print(comments[['Answers','Questions']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "!pip install matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Define a list of documents to use for topic modeling\n",
    "documents = comments['Comments'].values.tolist()\n",
    "\n",
    "# Preprocess the documents by tokenizing and removing stop words\n",
    "stopwords = set(gensim.parsing.preprocessing.STOPWORDS)\n",
    "texts = [[word for word in document.lower().split() if word not in stopwords]\n",
    "         for document in documents]\n",
    "\n",
    "# Create a dictionary and bag-of-words representation of the documents\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train an LDA model on the corpus\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=3, passes=10)\n",
    "\n",
    "# Print the top words for each topic\n",
    "for topic in lda_model.print_topics():\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPIC MODELLING: does not look very insightful\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Generate a word cloud for the first topic\n",
    "topic_words = lda_model.show_topic(0, 30)\n",
    "wordcloud = WordCloud(width=800, height=400).generate_from_frequencies(dict(topic_words))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis, topic modelling, QA, keyword extraction/ner\n",
    "\n",
    "# self trained model, online dataset\n",
    "# fine tuning an existing model, self labelled dataset\n",
    "# self trained model, self labelled dataset\n",
    "\n",
    "# possible insights: if a certain programme has more negative comments, can reconsider the curriculum of the programe\n",
    "# other options for future consideration: amazon comprehend, google natural language api\n",
    "# limitation: word cannot be too long"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
