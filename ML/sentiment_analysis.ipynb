{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sentiment Analysis (Evaluations)</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DATA EXPLORATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. PRE-TRAINED MODELS: COMPARING PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This medical student demonstrated excellent pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They remained calm and composed under pressure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This medical student showed excellent critical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They were able to prioritize tasks effectively...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This medical student showed excellent communic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>They were able to adapt to unexpected challeng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This medical student showed excellent attentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>They were able to work independently, demonstr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This medical student showed excellent clinical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>They were able to manage complex patient cases...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>This medical student has excellent communicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This medical student showed a lack of commitme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>They were unable to work effectively under pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This medical student demonstrated a lack of un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>They were frequently uncooperative and difficu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>This medical student showed little interest in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>They were unable to effectively collaborate wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>This medical student demonstrated unprofession...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>This medical student demonstrated average comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>They were able to correctly diagnose the patie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comments\n",
       "0   This medical student demonstrated excellent pr...\n",
       "1   They remained calm and composed under pressure...\n",
       "2   This medical student showed excellent critical...\n",
       "3   They were able to prioritize tasks effectively...\n",
       "4   This medical student showed excellent communic...\n",
       "5   They were able to adapt to unexpected challeng...\n",
       "6   This medical student showed excellent attentio...\n",
       "7   They were able to work independently, demonstr...\n",
       "8   This medical student showed excellent clinical...\n",
       "9   They were able to manage complex patient cases...\n",
       "10  This medical student has excellent communicati...\n",
       "11  This medical student showed a lack of commitme...\n",
       "12  They were unable to work effectively under pre...\n",
       "13  This medical student demonstrated a lack of un...\n",
       "14  They were frequently uncooperative and difficu...\n",
       "15  This medical student showed little interest in...\n",
       "16  They were unable to effectively collaborate wi...\n",
       "17  This medical student demonstrated unprofession...\n",
       "18  This medical student demonstrated average comm...\n",
       "19  They were able to correctly diagnose the patie..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments=pd.read_excel('comments.xlsx')\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Using cached vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp310-cp310-win_amd64.whl (97 kB)\n",
      "     ---------------------------------------- 0.0/97.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 97.1/97.1 kB 5.8 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests, vaderSentiment\n",
      "Successfully installed certifi-2022.12.7 charset-normalizer-3.1.0 idna-3.4 requests-2.28.2 urllib3-1.26.15 vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "#install vaderSentimentlibrary\n",
    "!pip install vaderSentiment\n",
    "\n",
    "#import the library\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#calculate the negative, positive, neutral and compound scores, plus verbal evaluation\n",
    "def sentiment_vader(sentence):\n",
    "\n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    negative = sentiment_dict['neg']\n",
    "    neutral = sentiment_dict['neu']\n",
    "    positive = sentiment_dict['pos']\n",
    "    compound = sentiment_dict['compound']\n",
    "\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        overall_sentiment = \"Positive\"\n",
    "\n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        overall_sentiment = \"Negative\"\n",
    "\n",
    "    else :\n",
    "        overall_sentiment = \"Neutral\"\n",
    "  \n",
    "    return negative, neutral, positive, compound, overall_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.181, 0.819, 0.0, -0.4767, 'Negative')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=comments.apply(lambda x: sentiment_vader(x['Comments']),axis=1)\n",
    "a.iloc[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "     ---------------------------------------- 0.0/636.8 kB ? eta -:--:--\n",
      "     -------------------------------- ---- 563.2/636.8 kB 12.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- 636.8/636.8 kB 10.1 MB/s eta 0:00:00\n",
      "Collecting nltk>=3.1\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     --------------------- ------------------ 0.8/1.5 MB 26.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 24.2 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 0.0/77.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 77.1/77.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp310-cp310-win_amd64.whl (267 kB)\n",
      "     ---------------------------------------- 0.0/267.7 kB ? eta -:--:--\n",
      "     -------------------------- ---------- 194.6/267.7 kB 12.3 MB/s eta 0:00:01\n",
      "     -------------------------- ---------- 194.6/267.7 kB 12.3 MB/s eta 0:00:01\n",
      "     -------------------------- ---------- 194.6/267.7 kB 12.3 MB/s eta 0:00:01\n",
      "     -------------------------- ---------- 194.6/267.7 kB 12.3 MB/s eta 0:00:01\n",
      "     -------------------------- ---------- 194.6/267.7 kB 12.3 MB/s eta 0:00:01\n",
      "     -------------------------- ---------- 194.6/267.7 kB 12.3 MB/s eta 0:00:01\n",
      "     -------------------------- ---------- 194.6/267.7 kB 12.3 MB/s eta 0:00:01\n",
      "     --------------------------- -------- 204.8/267.7 kB 541.9 kB/s eta 0:00:01\n",
      "     ------------------------------------ 267.7/267.7 kB 660.2 kB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ---------------------------------------- 0.0/298.0 kB ? eta -:--:--\n",
      "     ------------------------------------- 298.0/298.0 kB 18.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\feryo\\onedrive\\documents\\github\\fyp-goodhealth\\.venv\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, joblib, nltk, textblob\n",
      "Successfully installed joblib-1.2.0 nltk-3.8.1 regex-2022.10.31 textblob-0.17.1 tqdm-4.65.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# install textblob\n",
    "!pip install textblob\n",
    "\n",
    "# import it\n",
    "from textblob import TextBlob\n",
    "\n",
    "#call the classifier\n",
    "def sentiment_texblob(row):\n",
    "  \n",
    "    classifier = TextBlob(row)\n",
    "    polarity = classifier.sentiment.polarity\n",
    "    subjectivity = classifier.sentiment.subjectivity\n",
    "    \n",
    "    return polarity,subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     (0.4833333333333333, 0.575)\n",
       "1                   (-0.09999999999999998, 0.875)\n",
       "2                                    (0.225, 0.7)\n",
       "3        (0.3666666666666667, 0.8083333333333332)\n",
       "4      (0.29500000000000004, 0.43499999999999994)\n",
       "                          ...                    \n",
       "204     (0.06727272727272726, 0.5909090909090909)\n",
       "205     (0.37878787878787873, 0.6515151515151515)\n",
       "206                                   (0.1, 0.45)\n",
       "207      (0.4454545454545455, 0.5181818181818182)\n",
       "208                   (-0.07500000000000001, 0.6)\n",
       "Length: 209, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=comments.apply(lambda x: sentiment_texblob(x['Comments']),axis=1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install happytransformer\n",
    "from happytransformer import HappyTextClassification\n",
    "happy_tc=HappyTextClassification(model_type='DISTILBERT',model_name='distilbert-base-uncased-finetuned-sst-2-english',num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=comments.apply(lambda x: happy_tc.classify_text(x['Comments']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      TextClassificationResult(label='POSITIVE', sco...\n",
       "1      TextClassificationResult(label='POSITIVE', sco...\n",
       "2      TextClassificationResult(label='POSITIVE', sco...\n",
       "3      TextClassificationResult(label='POSITIVE', sco...\n",
       "4      TextClassificationResult(label='POSITIVE', sco...\n",
       "                             ...                        \n",
       "204    TextClassificationResult(label='POSITIVE', sco...\n",
       "205    TextClassificationResult(label='NEGATIVE', sco...\n",
       "206    TextClassificationResult(label='POSITIVE', sco...\n",
       "207    TextClassificationResult(label='NEGATIVE', sco...\n",
       "208    TextClassificationResult(label='POSITIVE', sco...\n",
       "Length: 209, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "         Supervised learning is the machine learning task of \n",
    "         learning a function that maps an input to an output based \n",
    "         on example input-output pairs.[1] It infers a function \n",
    "         from labeled training data consisting of a set of \n",
    "         training examples.[2] In supervised learning, each \n",
    "         example is a pair consisting of an input object \n",
    "         (typically a vector) and a desired output value (also \n",
    "         called the supervisory signal). A supervised learning \n",
    "         algorithm analyzes the training data and produces an \n",
    "         inferred function, which can be used for mapping new \n",
    "         examples. An optimal scenario will allow for the algorithm \n",
    "         to correctly determine the class labels for unseen \n",
    "         instances. This requires the learning algorithm to  \n",
    "         generalize from the training data to unseen situations \n",
    "         in a 'reasonable' way (see inductive bias).\n",
    "      \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2936 sha256=10dffa1c852006c2ffa3d9224d9e07db48a869709fdea472b956024280987bc5\n",
      "  Stored in directory: c:\\users\\wongqihuiyve\\appdata\\local\\pip\\cache\\wheels\\f8\\e0\\3d\\9d0c2020c44a519b9f02ab4fa6d2a4a996c98d79ab2f569fa1\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0.post1\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 86.0/86.0 kB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 12.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.13.1-cp39-cp39-win_amd64.whl (162.5 MB)\n",
      "     -------------------------------------- 162.5/162.5 MB 6.5 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 17.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.9.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 17.8 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n",
      "     ------------------------------------- 199.2/199.2 kB 11.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.5)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 15.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wongqihuiyve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.11)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=4fae7f21e5737875fdfe05c77a84e1ac80bf55fdae0a13fc170588c2da7a0794\n",
      "  Stored in directory: c:\\users\\wongqihuiyve\\appdata\\local\\pip\\cache\\wheels\\71\\67\\06\\162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, torch, torchvision, huggingface-hub, transformers, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.13.2 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 torch-1.13.1 torchvision-0.14.1 transformers-4.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "n_gram_range = (1, 1)\n",
    "stop_words = \"english\"\n",
    "\n",
    "# Extract candidate words/phrases\n",
    "count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([doc])\n",
    "candidates = count.get_feature_names()\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "doc_embedding = model.encode([doc])\n",
    "candidate_embeddings = model.encode(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count= CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit(comments['Comments'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "candidates = count.get_feature_names()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedding = model.encode(comments['Comments'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embed=comments.apply(lambda x: model.encode(x['Comments']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_embeddings = model.encode(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-8.39351952e-01 -5.99134028e-01  7.35531390e-01  4.28534359e-01\n -5.54688513e-01 -9.75334167e-01 -2.08977208e-01 -7.60083675e-01\n  1.57578337e+00 -9.26830113e-01  1.25837028e+00  4.37889189e-01\n  7.96425164e-01  7.16393054e-01  4.42168444e-01 -1.91637918e-01\n  5.62849760e-01  2.64096320e-01 -6.67578697e-01 -2.22169265e-01\n -1.86430907e-03 -8.73347938e-01  5.55210896e-02  1.25959384e+00\n  2.46438026e-01 -6.46822274e-01  3.51742417e-01  5.17586112e-01\n  2.35641122e-01  4.45929378e-01  7.21871555e-02 -1.25017023e+00\n -2.73595989e-01  1.05292070e+00  1.58898294e-01  4.07843858e-01\n  1.36208522e+00  9.80053902e-01 -4.58101273e-01 -3.13274711e-02\n -3.69800329e-01 -2.73410976e-01  4.91810679e-01  5.64341247e-01\n -2.48707607e-01 -8.10268104e-01 -9.96507347e-01 -3.56944412e-01\n -8.47017586e-01 -3.33932526e-02 -4.68775064e-01  2.55755037e-01\n  8.28089342e-02  6.39742240e-02 -2.35222578e-01 -4.14844662e-01\n  2.78825108e-02 -1.12726234e-01 -7.96506032e-02 -2.67586797e-01\n  9.70064178e-02  4.35388237e-01 -3.36050987e-01  8.92266110e-02\n  7.30654418e-01  3.22408110e-01 -3.20912629e-01  7.15961158e-01\n  4.94658858e-01 -2.04103068e-01 -4.95521545e-01 -2.45055988e-01\n -6.80305064e-01 -1.40473759e+00 -4.70243096e-01 -8.96033466e-01\n  5.68762243e-01 -4.16427761e-01  2.74865359e-01 -5.46762049e-01\n -4.01460558e-01 -8.05420708e-03 -3.00268561e-01 -1.46683738e-01\n  1.29753545e-01  5.78718066e-01  4.52695251e-01 -5.47355354e-01\n  3.23157310e-01  1.05631483e+00 -5.74298441e-01 -1.69239566e-01\n -3.24382395e-01 -5.02774715e-01 -4.66857284e-01 -6.77087486e-01\n  2.42149293e-01 -6.76008463e-01 -2.27287233e-01 -4.59914356e-01\n -3.97110552e-01  9.17441547e-02  4.28427845e-01  1.84263349e-01\n  2.77267992e-01  9.47877586e-01  2.16353521e-01 -5.60393453e-01\n  3.78176570e-03 -3.98220979e-02 -4.22414213e-01  3.14284295e-01\n -1.06510878e-01 -6.33354127e-01 -2.79773831e-01 -9.50834751e-02\n -4.31614280e-01  3.73502105e-01  1.74347812e-03  7.45102227e-01\n  6.36245251e-01 -4.47076350e-01  9.87185180e-01  8.84086132e-01\n -2.35151708e-01  7.91549027e-01 -1.88830510e-01  4.87212926e-01\n -6.96722746e-01 -7.53185511e-01 -5.58692992e-01  7.66411841e-01\n  4.27866578e-01  1.29827276e-01  9.95179355e-01 -5.79648793e-01\n -5.05852222e-01 -2.46609241e-04 -7.22046912e-01  6.34517252e-01\n -5.43904364e-01 -5.36826849e-01  2.68783450e-01 -1.52106524e-01\n  4.26201105e-01 -2.02622414e-01 -3.62085253e-01 -1.02275586e+00\n -3.00307363e-01 -1.51662588e-01 -9.49643910e-01 -4.21961218e-01\n -2.19930366e-01  8.83081034e-02  8.81213367e-01  9.44838345e-01\n  7.06265075e-03 -2.81064302e-01 -3.56856197e-01 -7.86314309e-01\n -5.80334544e-01  1.42902926e-01  3.09561938e-01  5.38006306e-01\n -2.63427526e-01 -3.91045421e-01  7.83273399e-01 -9.22063828e-01\n -2.13017806e-01  6.96638584e-01  1.04065895e-01  2.10596770e-02\n  3.96155208e-01  6.60316586e-01 -2.20033184e-01  4.68654424e-01\n -3.44748497e-01 -5.15610218e-01 -6.97911456e-02 -8.95536602e-01\n  3.46942544e-01  8.02198887e-01 -5.67548238e-02 -2.47383952e-01\n -7.33626604e-01 -5.94732940e-01  6.52282238e-01 -2.36292675e-01\n -7.92637765e-01  2.95655042e-01  4.66784835e-01  5.93982518e-01\n -6.67751729e-01  1.83603927e-01  1.33540535e+00  4.22858924e-01\n -7.31567144e-01  1.50785446e+00 -6.24502838e-01 -4.47792381e-01\n  3.28085452e-01 -2.63496608e-01 -6.73318565e-01 -2.43482545e-01\n -2.41559874e-02 -1.67350397e-01  5.67859113e-01 -1.19868733e-01\n -1.06109113e-01 -4.71831232e-01 -5.99151313e-01  9.47713196e-01\n  1.34940341e-01 -2.42828175e-01 -3.91875178e-01  1.31042647e+00\n -1.28377736e+00 -1.79769516e-01 -4.53139730e-02  1.85651049e-01\n  2.07904458e-01 -8.55304301e-01  8.67219985e-01 -8.73290479e-01\n  1.94916174e-01 -9.27061260e-01 -5.93221545e-01  6.28932714e-01\n  2.33712181e-01 -2.68402606e-01 -1.69775233e-01  5.65857232e-01\n  1.84462190e-01  7.21325457e-01 -2.05375627e-01 -2.55842835e-01\n -6.21618450e-01 -9.80763912e-01  1.69946480e+00 -7.31359184e-01\n -1.84957683e-01 -2.33551249e-01  1.62332261e-03  4.60098773e-01\n  1.08513720e-01  1.18418109e+00 -2.82455117e-01  3.11339557e-01\n  1.18450904e+00  4.01601881e-01 -6.87527180e-01 -4.17740345e-01\n -8.66839468e-01 -8.96550119e-02  2.94855982e-01 -1.24872839e+00\n -4.58046347e-01 -5.22294104e-01 -1.01897621e+00  8.94053519e-01\n -1.55213043e-01  3.46439689e-01  8.09222043e-01 -4.43074703e-01\n -2.91285545e-01 -8.02377641e-01 -1.62531567e+00 -1.05827820e+00\n  1.19594507e-01  4.99921203e-01 -1.03221822e+00 -4.42845017e-01\n  6.81137621e-01 -1.10840929e+00  2.78962016e-01 -5.31707823e-01\n -1.12366128e+00 -3.95458378e-02  8.15284491e-01 -1.03635348e-01\n  4.22007442e-02  3.15775871e-01  7.41837740e-01 -1.25937998e+00\n  6.61592662e-01 -9.03174654e-02  1.55650586e-01 -5.62999427e-01\n -5.54690778e-01 -4.04014200e-01 -5.25807850e-02 -3.24111313e-01\n -1.45228565e-01  9.49055493e-01  1.42070580e+00 -1.16464865e+00\n  9.76840556e-01  5.80786288e-01 -1.64976880e-01 -6.70767501e-02\n -1.11130245e-01  1.01378429e+00  7.33383179e-01 -1.02460600e-01\n  1.48249194e-01  5.63437231e-02  7.00703144e-01 -9.58216965e-01\n  8.40172842e-02 -5.86882055e-01  7.27733374e-01 -1.25662640e-01\n  1.54425815e-01  2.98336357e-01  9.12243366e-01 -4.82261091e-01\n -6.16474509e-01  1.28581822e-01 -8.65159273e-01  8.01600516e-01\n -2.63213277e-01  9.02164578e-02  2.88467079e-01 -9.17617753e-02\n  1.05314755e+00  7.32649505e-01 -5.27104378e-01  9.18060064e-01\n -4.17132266e-02 -1.10319293e+00  1.24677636e-01  1.26631871e-01\n  5.36229312e-01  4.86457855e-01  3.54739547e-01 -8.30750167e-02\n  9.73416343e-02  4.28673744e-01  3.32929611e-01  3.45178932e-01\n  2.10426524e-01 -6.29652292e-02  4.25854325e-01 -2.26434097e-01\n  8.69196713e-01 -3.97416919e-01 -5.77921867e-01 -6.39976442e-01\n  1.74578741e-01 -2.13673934e-02  3.80444139e-01  2.29795471e-01\n  3.23934108e-01 -4.71453339e-01  5.82831144e-01 -4.26702857e-01\n  5.65912239e-02  1.67266831e-01  2.05695465e-01  6.22241914e-01\n  1.02185524e+00  7.75680542e-01 -5.23871137e-03  1.75471827e-01\n  1.13722169e+00 -1.44936606e-01 -1.16921949e+00 -4.10456173e-02\n -3.15735728e-01 -5.38793504e-01 -6.96846485e-01  2.33616427e-01\n  5.40765285e-01 -4.74781692e-02  4.54449803e-01 -2.59137064e-01\n  3.37127954e-01  5.66909611e-01 -3.15227658e-01  9.75978002e-02\n -8.30933377e-02  2.68287987e-01  4.98524576e-01  4.88509089e-01\n -2.19902053e-01 -1.16188610e+00 -4.38140869e-01  1.82140529e-01\n -1.05508767e-01 -6.66555226e-01  5.05487025e-01 -2.20096245e-01\n  6.90853447e-02 -2.76219338e-01  7.34687269e-01 -2.45867178e-01\n -1.19723225e+00  8.69160414e-01 -3.54296446e-01 -1.54510581e+00\n  1.09019935e+00  7.24604949e-02 -1.31222829e-01  1.77517462e+00\n  3.80440563e-01  6.45149723e-02 -1.43758925e-02 -1.33169603e+00\n  1.18164027e+00 -1.91012083e-03 -1.20900711e-02 -1.49718076e-02\n  2.94673353e-01  3.02605003e-01 -5.38121104e-01 -6.98991120e-01\n -8.16868842e-02 -4.68365461e-01 -1.82433951e+00 -5.83767295e-02\n  2.89561182e-01  1.01173818e+00 -3.84254307e-01  4.13884312e-01\n  1.18467361e-02 -4.28395957e-01  1.00534832e+00 -8.46118033e-01\n -5.30363083e-01  7.05016792e-01 -8.40459764e-02 -1.87651459e-02\n  4.73222174e-02  4.24999952e-01 -2.15072513e-01  1.93653151e-01\n  2.11120501e-01  6.69192493e-01 -5.57445109e-01 -8.49274158e-01\n -5.02875149e-02  7.28066206e-01  2.88142174e-01 -1.12652825e-02\n -4.28405792e-01 -8.79820526e-01  5.86173713e-01  4.52773005e-01\n -2.40500625e-02  4.32377428e-01  6.58926308e-01 -3.98756266e-01\n  4.37426835e-01  1.13103211e-01  6.60836399e-02  5.07023633e-01\n -9.17623103e-01  1.26694572e+00 -5.26426613e-01  4.68359023e-01\n  4.32937294e-01 -7.92235076e-01  1.45058766e-01  3.62952739e-01\n -1.25712380e-01  7.56587014e-02  1.51381716e-01  6.09270632e-01\n  1.04481602e+00 -3.37592036e-01  5.65709621e-02  5.83923936e-01\n  1.66026711e-01  4.21339393e-01 -7.54300416e-01 -4.07477140e-01\n  1.00594199e+00  4.88734394e-01  5.14033854e-01 -1.06753981e+00\n  2.70726323e-01 -1.17888939e+00 -4.91200924e-01 -1.04575932e-01\n  4.46933120e-01  1.05626845e+00 -4.13232565e-01  2.34797433e-01\n -1.00794947e+00 -2.21049333e+00 -4.87197638e-01  1.36911914e-01\n  1.76553801e-01  5.90046287e-01 -2.97521234e-01  2.42328003e-01\n -3.61816317e-01  5.42905509e-01 -4.18750376e-01 -1.36326328e-01\n -3.10693055e-01 -1.21193659e+00  7.51944780e-02  3.59252006e-01\n  9.53492880e-01 -6.51134729e-01  1.76659390e-01 -3.52825314e-01\n -3.36720437e-01  5.33775032e-01 -8.16596925e-01 -6.94378197e-01\n  7.61938334e-01 -6.70664072e-01 -4.20670547e-02 -5.37964106e-01\n -6.67222321e-01  3.36285591e-01  1.50100553e+00  9.16024446e-01\n -3.17179143e-01 -1.17092896e+00  5.88813007e-01 -3.10145110e-01\n  4.30541903e-01 -3.98631811e-01 -3.70774508e-01  2.64739990e-03\n -4.25451040e-01  6.97488785e-01  3.23488563e-01 -5.89166582e-01\n -4.91888911e-01  2.46325806e-01  3.65666300e-01  1.32372594e+00\n  4.48103517e-01 -5.02981126e-01  2.89712101e-01  5.45461476e-01\n  2.41935253e-01 -7.22529516e-02  5.89104593e-02 -6.33606240e-02\n -5.82452536e-01 -5.37828445e-01  3.96217465e-01  6.09855592e-01\n -9.99320745e-01  1.98332191e-01  2.73627788e-01  3.99792790e-01\n  1.12543933e-01 -8.50750972e-03  2.64186531e-01 -1.61145732e-01\n  8.90687764e-01 -5.97553790e-01 -2.74796430e-02  3.12547237e-01\n -1.03662360e+00  2.27956772e-01  2.15509161e-01 -1.09649049e-02\n  9.54755116e-03 -8.57979119e-01 -7.29743779e-01 -3.80896002e-01\n -2.48087361e-01 -1.32848695e-01 -8.63905728e-01  6.61903024e-01\n -7.78729916e-01 -3.43880743e-01  3.57578471e-02  1.77227676e-01\n -7.23197758e-01 -2.48130038e-01 -3.33234698e-01  3.40013981e-01\n  3.15655351e-01 -6.96263731e-01  2.46869132e-01 -3.51039559e-01\n  4.61768031e-01 -5.43961763e-01 -7.52921030e-02  3.96929026e-01\n -1.18540376e-02  6.22625411e-01 -1.40457904e+00 -1.62947282e-01\n  4.43710238e-01 -6.86004400e-01  3.89728159e-01  1.99367002e-01\n  2.39067867e-01  2.79072672e-01 -1.13998830e-01 -1.43756762e-01\n -4.26777126e-03 -9.37446535e-01  1.05541241e+00 -1.24980755e-01\n  1.72967327e+00 -7.69871891e-01 -1.61969528e-01 -1.55179098e-01\n  1.92113981e-01  2.23932552e+00  8.58635962e-01 -1.48834124e-01\n -5.08456171e-01  1.67959440e+00  4.18046713e-01 -1.55338943e+00\n -1.07927954e+00 -1.46979225e+00 -3.94724220e-01 -2.63204485e-01\n -9.10546780e-01 -2.16211125e-01 -9.05813396e-01 -3.36339086e-01\n  7.26886094e-01 -1.29287529e+00 -8.16430092e-01  2.86476374e-01\n  3.41821283e-01 -1.02494287e+00  2.31857300e-01  5.72979897e-02\n -7.05826655e-02  6.67653620e-01 -1.50182211e+00 -4.82703060e-01\n -5.41809380e-01  4.10887003e-01  2.75872517e-02 -8.83709729e-01\n -5.63697100e-01 -6.17168367e-01 -2.05638155e-01 -9.39078629e-02\n  9.62015629e-01  7.17940509e-01  2.15831995e-01  1.85279891e-01\n -1.31726992e+00  1.28090942e+00 -3.27328295e-01  6.78387344e-01\n -2.16631498e-02 -8.50967988e-02 -6.90494955e-01  5.28340995e-01\n -1.59499973e-01  2.03687355e-01 -2.65600562e-01 -1.09969927e-02\n -3.28794986e-01  5.93464971e-02  5.39868057e-01 -5.43490611e-02\n -1.66525170e-02  1.40022987e-03 -3.43882181e-02  7.95176566e-01\n -5.96367240e-01  2.74274230e-01  5.14137208e-01  6.12566650e-01\n -1.66757429e+00  3.29545923e-02  1.03097165e+00  9.41982493e-02\n -4.71690059e-01 -1.92584515e-01 -7.44893014e-01 -1.32294461e-01\n -1.05797194e-01  3.42650741e-01 -7.81079471e-01 -3.12433153e-01\n -8.77919272e-02 -2.20040396e-01  5.06045401e-01  1.23609376e+00\n  7.41704404e-01 -7.66023338e-01  1.32543012e-01 -5.86530030e-01\n -3.82762961e-02  3.52180570e-01 -4.37403955e-02 -1.14311218e-01\n  9.78739094e-03 -1.23633313e+00 -1.15101218e-01  3.20760012e-02\n  1.74272135e-01 -4.10250038e-01  2.05029383e-01 -9.06047165e-01\n -3.59445363e-01  6.76687419e-01  5.88162959e-01  6.57094359e-01\n  2.54771203e-01 -1.43009102e+00  2.28097185e-01  3.83354753e-01\n  1.17684351e-02 -4.91154790e-01  2.70628929e-01 -3.19939107e-01\n  6.59234583e-01  1.10244058e-01  3.90963674e-01  1.09355342e+00\n  4.85608310e-01 -5.46025932e-01 -1.66415945e-01  3.25798661e-01\n  1.85860246e-02  2.00821444e-01  2.14615107e-01 -3.79878521e-01\n  1.29534578e+00 -3.64043325e-01 -8.02435577e-01 -2.89170593e-01\n -2.05581293e-01  6.59127653e-01 -1.88860878e-01  9.44128409e-02\n -9.75059450e-01  5.77316701e-01 -2.96657890e-01  1.98953245e-02\n -2.61993527e-01  3.69351298e-01 -3.45918298e-01 -1.52633226e+00\n -6.31918848e-01  2.93215394e-01 -1.44141006e+00  3.20561677e-01\n -2.38790706e-01 -8.06646124e-02 -2.09952489e-01  7.11289465e-01\n  2.56887496e-01 -2.13376001e-01  2.39870027e-01  4.47477430e-01\n -3.73850316e-01 -9.57814038e-01  2.46412065e-02 -1.24982989e+00\n  7.35841095e-01  2.50950336e-01 -4.23492789e-01 -4.00588959e-01\n -1.49981335e-01  4.55261827e-01  1.01036108e+00 -2.72999495e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20328\\494032937.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Embed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Comments'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtop_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcomments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Distances'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Embed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# keyword_arr=[]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8846\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8847\u001b[0m         )\n\u001b[1;32m-> 8848\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"apply\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8850\u001b[0m     def applymap(\n",
      "\u001b[1;32mc:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    871\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    874\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20328\\494032937.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Embed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Comments'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtop_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcomments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Distances'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Embed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# keyword_arr=[]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[1;31m# to avoid recursive import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    154\u001b[0m         )\n\u001b[0;32m    155\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         X = check_array(\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    770\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-8.39351952e-01 -5.99134028e-01  7.35531390e-01  4.28534359e-01\n -5.54688513e-01 -9.75334167e-01 -2.08977208e-01 -7.60083675e-01\n  1.57578337e+00 -9.26830113e-01  1.25837028e+00  4.37889189e-01\n  7.96425164e-01  7.16393054e-01  4.42168444e-01 -1.91637918e-01\n  5.62849760e-01  2.64096320e-01 -6.67578697e-01 -2.22169265e-01\n -1.86430907e-03 -8.73347938e-01  5.55210896e-02  1.25959384e+00\n  2.46438026e-01 -6.46822274e-01  3.51742417e-01  5.17586112e-01\n  2.35641122e-01  4.45929378e-01  7.21871555e-02 -1.25017023e+00\n -2.73595989e-01  1.05292070e+00  1.58898294e-01  4.07843858e-01\n  1.36208522e+00  9.80053902e-01 -4.58101273e-01 -3.13274711e-02\n -3.69800329e-01 -2.73410976e-01  4.91810679e-01  5.64341247e-01\n -2.48707607e-01 -8.10268104e-01 -9.96507347e-01 -3.56944412e-01\n -8.47017586e-01 -3.33932526e-02 -4.68775064e-01  2.55755037e-01\n  8.28089342e-02  6.39742240e-02 -2.35222578e-01 -4.14844662e-01\n  2.78825108e-02 -1.12726234e-01 -7.96506032e-02 -2.67586797e-01\n  9.70064178e-02  4.35388237e-01 -3.36050987e-01  8.92266110e-02\n  7.30654418e-01  3.22408110e-01 -3.20912629e-01  7.15961158e-01\n  4.94658858e-01 -2.04103068e-01 -4.95521545e-01 -2.45055988e-01\n -6.80305064e-01 -1.40473759e+00 -4.70243096e-01 -8.96033466e-01\n  5.68762243e-01 -4.16427761e-01  2.74865359e-01 -5.46762049e-01\n -4.01460558e-01 -8.05420708e-03 -3.00268561e-01 -1.46683738e-01\n  1.29753545e-01  5.78718066e-01  4.52695251e-01 -5.47355354e-01\n  3.23157310e-01  1.05631483e+00 -5.74298441e-01 -1.69239566e-01\n -3.24382395e-01 -5.02774715e-01 -4.66857284e-01 -6.77087486e-01\n  2.42149293e-01 -6.76008463e-01 -2.27287233e-01 -4.59914356e-01\n -3.97110552e-01  9.17441547e-02  4.28427845e-01  1.84263349e-01\n  2.77267992e-01  9.47877586e-01  2.16353521e-01 -5.60393453e-01\n  3.78176570e-03 -3.98220979e-02 -4.22414213e-01  3.14284295e-01\n -1.06510878e-01 -6.33354127e-01 -2.79773831e-01 -9.50834751e-02\n -4.31614280e-01  3.73502105e-01  1.74347812e-03  7.45102227e-01\n  6.36245251e-01 -4.47076350e-01  9.87185180e-01  8.84086132e-01\n -2.35151708e-01  7.91549027e-01 -1.88830510e-01  4.87212926e-01\n -6.96722746e-01 -7.53185511e-01 -5.58692992e-01  7.66411841e-01\n  4.27866578e-01  1.29827276e-01  9.95179355e-01 -5.79648793e-01\n -5.05852222e-01 -2.46609241e-04 -7.22046912e-01  6.34517252e-01\n -5.43904364e-01 -5.36826849e-01  2.68783450e-01 -1.52106524e-01\n  4.26201105e-01 -2.02622414e-01 -3.62085253e-01 -1.02275586e+00\n -3.00307363e-01 -1.51662588e-01 -9.49643910e-01 -4.21961218e-01\n -2.19930366e-01  8.83081034e-02  8.81213367e-01  9.44838345e-01\n  7.06265075e-03 -2.81064302e-01 -3.56856197e-01 -7.86314309e-01\n -5.80334544e-01  1.42902926e-01  3.09561938e-01  5.38006306e-01\n -2.63427526e-01 -3.91045421e-01  7.83273399e-01 -9.22063828e-01\n -2.13017806e-01  6.96638584e-01  1.04065895e-01  2.10596770e-02\n  3.96155208e-01  6.60316586e-01 -2.20033184e-01  4.68654424e-01\n -3.44748497e-01 -5.15610218e-01 -6.97911456e-02 -8.95536602e-01\n  3.46942544e-01  8.02198887e-01 -5.67548238e-02 -2.47383952e-01\n -7.33626604e-01 -5.94732940e-01  6.52282238e-01 -2.36292675e-01\n -7.92637765e-01  2.95655042e-01  4.66784835e-01  5.93982518e-01\n -6.67751729e-01  1.83603927e-01  1.33540535e+00  4.22858924e-01\n -7.31567144e-01  1.50785446e+00 -6.24502838e-01 -4.47792381e-01\n  3.28085452e-01 -2.63496608e-01 -6.73318565e-01 -2.43482545e-01\n -2.41559874e-02 -1.67350397e-01  5.67859113e-01 -1.19868733e-01\n -1.06109113e-01 -4.71831232e-01 -5.99151313e-01  9.47713196e-01\n  1.34940341e-01 -2.42828175e-01 -3.91875178e-01  1.31042647e+00\n -1.28377736e+00 -1.79769516e-01 -4.53139730e-02  1.85651049e-01\n  2.07904458e-01 -8.55304301e-01  8.67219985e-01 -8.73290479e-01\n  1.94916174e-01 -9.27061260e-01 -5.93221545e-01  6.28932714e-01\n  2.33712181e-01 -2.68402606e-01 -1.69775233e-01  5.65857232e-01\n  1.84462190e-01  7.21325457e-01 -2.05375627e-01 -2.55842835e-01\n -6.21618450e-01 -9.80763912e-01  1.69946480e+00 -7.31359184e-01\n -1.84957683e-01 -2.33551249e-01  1.62332261e-03  4.60098773e-01\n  1.08513720e-01  1.18418109e+00 -2.82455117e-01  3.11339557e-01\n  1.18450904e+00  4.01601881e-01 -6.87527180e-01 -4.17740345e-01\n -8.66839468e-01 -8.96550119e-02  2.94855982e-01 -1.24872839e+00\n -4.58046347e-01 -5.22294104e-01 -1.01897621e+00  8.94053519e-01\n -1.55213043e-01  3.46439689e-01  8.09222043e-01 -4.43074703e-01\n -2.91285545e-01 -8.02377641e-01 -1.62531567e+00 -1.05827820e+00\n  1.19594507e-01  4.99921203e-01 -1.03221822e+00 -4.42845017e-01\n  6.81137621e-01 -1.10840929e+00  2.78962016e-01 -5.31707823e-01\n -1.12366128e+00 -3.95458378e-02  8.15284491e-01 -1.03635348e-01\n  4.22007442e-02  3.15775871e-01  7.41837740e-01 -1.25937998e+00\n  6.61592662e-01 -9.03174654e-02  1.55650586e-01 -5.62999427e-01\n -5.54690778e-01 -4.04014200e-01 -5.25807850e-02 -3.24111313e-01\n -1.45228565e-01  9.49055493e-01  1.42070580e+00 -1.16464865e+00\n  9.76840556e-01  5.80786288e-01 -1.64976880e-01 -6.70767501e-02\n -1.11130245e-01  1.01378429e+00  7.33383179e-01 -1.02460600e-01\n  1.48249194e-01  5.63437231e-02  7.00703144e-01 -9.58216965e-01\n  8.40172842e-02 -5.86882055e-01  7.27733374e-01 -1.25662640e-01\n  1.54425815e-01  2.98336357e-01  9.12243366e-01 -4.82261091e-01\n -6.16474509e-01  1.28581822e-01 -8.65159273e-01  8.01600516e-01\n -2.63213277e-01  9.02164578e-02  2.88467079e-01 -9.17617753e-02\n  1.05314755e+00  7.32649505e-01 -5.27104378e-01  9.18060064e-01\n -4.17132266e-02 -1.10319293e+00  1.24677636e-01  1.26631871e-01\n  5.36229312e-01  4.86457855e-01  3.54739547e-01 -8.30750167e-02\n  9.73416343e-02  4.28673744e-01  3.32929611e-01  3.45178932e-01\n  2.10426524e-01 -6.29652292e-02  4.25854325e-01 -2.26434097e-01\n  8.69196713e-01 -3.97416919e-01 -5.77921867e-01 -6.39976442e-01\n  1.74578741e-01 -2.13673934e-02  3.80444139e-01  2.29795471e-01\n  3.23934108e-01 -4.71453339e-01  5.82831144e-01 -4.26702857e-01\n  5.65912239e-02  1.67266831e-01  2.05695465e-01  6.22241914e-01\n  1.02185524e+00  7.75680542e-01 -5.23871137e-03  1.75471827e-01\n  1.13722169e+00 -1.44936606e-01 -1.16921949e+00 -4.10456173e-02\n -3.15735728e-01 -5.38793504e-01 -6.96846485e-01  2.33616427e-01\n  5.40765285e-01 -4.74781692e-02  4.54449803e-01 -2.59137064e-01\n  3.37127954e-01  5.66909611e-01 -3.15227658e-01  9.75978002e-02\n -8.30933377e-02  2.68287987e-01  4.98524576e-01  4.88509089e-01\n -2.19902053e-01 -1.16188610e+00 -4.38140869e-01  1.82140529e-01\n -1.05508767e-01 -6.66555226e-01  5.05487025e-01 -2.20096245e-01\n  6.90853447e-02 -2.76219338e-01  7.34687269e-01 -2.45867178e-01\n -1.19723225e+00  8.69160414e-01 -3.54296446e-01 -1.54510581e+00\n  1.09019935e+00  7.24604949e-02 -1.31222829e-01  1.77517462e+00\n  3.80440563e-01  6.45149723e-02 -1.43758925e-02 -1.33169603e+00\n  1.18164027e+00 -1.91012083e-03 -1.20900711e-02 -1.49718076e-02\n  2.94673353e-01  3.02605003e-01 -5.38121104e-01 -6.98991120e-01\n -8.16868842e-02 -4.68365461e-01 -1.82433951e+00 -5.83767295e-02\n  2.89561182e-01  1.01173818e+00 -3.84254307e-01  4.13884312e-01\n  1.18467361e-02 -4.28395957e-01  1.00534832e+00 -8.46118033e-01\n -5.30363083e-01  7.05016792e-01 -8.40459764e-02 -1.87651459e-02\n  4.73222174e-02  4.24999952e-01 -2.15072513e-01  1.93653151e-01\n  2.11120501e-01  6.69192493e-01 -5.57445109e-01 -8.49274158e-01\n -5.02875149e-02  7.28066206e-01  2.88142174e-01 -1.12652825e-02\n -4.28405792e-01 -8.79820526e-01  5.86173713e-01  4.52773005e-01\n -2.40500625e-02  4.32377428e-01  6.58926308e-01 -3.98756266e-01\n  4.37426835e-01  1.13103211e-01  6.60836399e-02  5.07023633e-01\n -9.17623103e-01  1.26694572e+00 -5.26426613e-01  4.68359023e-01\n  4.32937294e-01 -7.92235076e-01  1.45058766e-01  3.62952739e-01\n -1.25712380e-01  7.56587014e-02  1.51381716e-01  6.09270632e-01\n  1.04481602e+00 -3.37592036e-01  5.65709621e-02  5.83923936e-01\n  1.66026711e-01  4.21339393e-01 -7.54300416e-01 -4.07477140e-01\n  1.00594199e+00  4.88734394e-01  5.14033854e-01 -1.06753981e+00\n  2.70726323e-01 -1.17888939e+00 -4.91200924e-01 -1.04575932e-01\n  4.46933120e-01  1.05626845e+00 -4.13232565e-01  2.34797433e-01\n -1.00794947e+00 -2.21049333e+00 -4.87197638e-01  1.36911914e-01\n  1.76553801e-01  5.90046287e-01 -2.97521234e-01  2.42328003e-01\n -3.61816317e-01  5.42905509e-01 -4.18750376e-01 -1.36326328e-01\n -3.10693055e-01 -1.21193659e+00  7.51944780e-02  3.59252006e-01\n  9.53492880e-01 -6.51134729e-01  1.76659390e-01 -3.52825314e-01\n -3.36720437e-01  5.33775032e-01 -8.16596925e-01 -6.94378197e-01\n  7.61938334e-01 -6.70664072e-01 -4.20670547e-02 -5.37964106e-01\n -6.67222321e-01  3.36285591e-01  1.50100553e+00  9.16024446e-01\n -3.17179143e-01 -1.17092896e+00  5.88813007e-01 -3.10145110e-01\n  4.30541903e-01 -3.98631811e-01 -3.70774508e-01  2.64739990e-03\n -4.25451040e-01  6.97488785e-01  3.23488563e-01 -5.89166582e-01\n -4.91888911e-01  2.46325806e-01  3.65666300e-01  1.32372594e+00\n  4.48103517e-01 -5.02981126e-01  2.89712101e-01  5.45461476e-01\n  2.41935253e-01 -7.22529516e-02  5.89104593e-02 -6.33606240e-02\n -5.82452536e-01 -5.37828445e-01  3.96217465e-01  6.09855592e-01\n -9.99320745e-01  1.98332191e-01  2.73627788e-01  3.99792790e-01\n  1.12543933e-01 -8.50750972e-03  2.64186531e-01 -1.61145732e-01\n  8.90687764e-01 -5.97553790e-01 -2.74796430e-02  3.12547237e-01\n -1.03662360e+00  2.27956772e-01  2.15509161e-01 -1.09649049e-02\n  9.54755116e-03 -8.57979119e-01 -7.29743779e-01 -3.80896002e-01\n -2.48087361e-01 -1.32848695e-01 -8.63905728e-01  6.61903024e-01\n -7.78729916e-01 -3.43880743e-01  3.57578471e-02  1.77227676e-01\n -7.23197758e-01 -2.48130038e-01 -3.33234698e-01  3.40013981e-01\n  3.15655351e-01 -6.96263731e-01  2.46869132e-01 -3.51039559e-01\n  4.61768031e-01 -5.43961763e-01 -7.52921030e-02  3.96929026e-01\n -1.18540376e-02  6.22625411e-01 -1.40457904e+00 -1.62947282e-01\n  4.43710238e-01 -6.86004400e-01  3.89728159e-01  1.99367002e-01\n  2.39067867e-01  2.79072672e-01 -1.13998830e-01 -1.43756762e-01\n -4.26777126e-03 -9.37446535e-01  1.05541241e+00 -1.24980755e-01\n  1.72967327e+00 -7.69871891e-01 -1.61969528e-01 -1.55179098e-01\n  1.92113981e-01  2.23932552e+00  8.58635962e-01 -1.48834124e-01\n -5.08456171e-01  1.67959440e+00  4.18046713e-01 -1.55338943e+00\n -1.07927954e+00 -1.46979225e+00 -3.94724220e-01 -2.63204485e-01\n -9.10546780e-01 -2.16211125e-01 -9.05813396e-01 -3.36339086e-01\n  7.26886094e-01 -1.29287529e+00 -8.16430092e-01  2.86476374e-01\n  3.41821283e-01 -1.02494287e+00  2.31857300e-01  5.72979897e-02\n -7.05826655e-02  6.67653620e-01 -1.50182211e+00 -4.82703060e-01\n -5.41809380e-01  4.10887003e-01  2.75872517e-02 -8.83709729e-01\n -5.63697100e-01 -6.17168367e-01 -2.05638155e-01 -9.39078629e-02\n  9.62015629e-01  7.17940509e-01  2.15831995e-01  1.85279891e-01\n -1.31726992e+00  1.28090942e+00 -3.27328295e-01  6.78387344e-01\n -2.16631498e-02 -8.50967988e-02 -6.90494955e-01  5.28340995e-01\n -1.59499973e-01  2.03687355e-01 -2.65600562e-01 -1.09969927e-02\n -3.28794986e-01  5.93464971e-02  5.39868057e-01 -5.43490611e-02\n -1.66525170e-02  1.40022987e-03 -3.43882181e-02  7.95176566e-01\n -5.96367240e-01  2.74274230e-01  5.14137208e-01  6.12566650e-01\n -1.66757429e+00  3.29545923e-02  1.03097165e+00  9.41982493e-02\n -4.71690059e-01 -1.92584515e-01 -7.44893014e-01 -1.32294461e-01\n -1.05797194e-01  3.42650741e-01 -7.81079471e-01 -3.12433153e-01\n -8.77919272e-02 -2.20040396e-01  5.06045401e-01  1.23609376e+00\n  7.41704404e-01 -7.66023338e-01  1.32543012e-01 -5.86530030e-01\n -3.82762961e-02  3.52180570e-01 -4.37403955e-02 -1.14311218e-01\n  9.78739094e-03 -1.23633313e+00 -1.15101218e-01  3.20760012e-02\n  1.74272135e-01 -4.10250038e-01  2.05029383e-01 -9.06047165e-01\n -3.59445363e-01  6.76687419e-01  5.88162959e-01  6.57094359e-01\n  2.54771203e-01 -1.43009102e+00  2.28097185e-01  3.83354753e-01\n  1.17684351e-02 -4.91154790e-01  2.70628929e-01 -3.19939107e-01\n  6.59234583e-01  1.10244058e-01  3.90963674e-01  1.09355342e+00\n  4.85608310e-01 -5.46025932e-01 -1.66415945e-01  3.25798661e-01\n  1.85860246e-02  2.00821444e-01  2.14615107e-01 -3.79878521e-01\n  1.29534578e+00 -3.64043325e-01 -8.02435577e-01 -2.89170593e-01\n -2.05581293e-01  6.59127653e-01 -1.88860878e-01  9.44128409e-02\n -9.75059450e-01  5.77316701e-01 -2.96657890e-01  1.98953245e-02\n -2.61993527e-01  3.69351298e-01 -3.45918298e-01 -1.52633226e+00\n -6.31918848e-01  2.93215394e-01 -1.44141006e+00  3.20561677e-01\n -2.38790706e-01 -8.06646124e-02 -2.09952489e-01  7.11289465e-01\n  2.56887496e-01 -2.13376001e-01  2.39870027e-01  4.47477430e-01\n -3.73850316e-01 -9.57814038e-01  2.46412065e-02 -1.24982989e+00\n  7.35841095e-01  2.50950336e-01 -4.23492789e-01 -4.00588959e-01\n -1.49981335e-01  4.55261827e-01  1.01036108e+00 -2.72999495e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "top_n = 5\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "keyword_arr=[]\n",
    "for i in range(len(distances.argsort())):\n",
    "    keyword_arr.append( [candidates[index] for index in distances.argsort()[i][:top_n]])\n",
    "#keywords = [candidates[index] for index in distances.argsort()]\n",
    "keyword_arr\n",
    "#https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20328\\9876299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc_embed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5573\u001b[0m         ):\n\u001b[0;32m   5574\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "doc_embed.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learning', 'patient', 'medical', 'healthcare', 'exam']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     This medical student demonstrated excellent pr...\n",
       "1     They remained calm and composed under pressure...\n",
       "2     This medical student showed excellent critical...\n",
       "3     They were able to prioritize tasks effectively...\n",
       "4     This medical student showed excellent communic...\n",
       "5     They were able to adapt to unexpected challeng...\n",
       "6     This medical student showed excellent attentio...\n",
       "7     They were able to work independently, demonstr...\n",
       "8     This medical student showed excellent clinical...\n",
       "9     They were able to manage complex patient cases...\n",
       "10    This medical student has excellent communicati...\n",
       "11    This medical student showed a lack of commitme...\n",
       "12    They were unable to work effectively under pre...\n",
       "13    This medical student demonstrated a lack of un...\n",
       "14    They were frequently uncooperative and difficu...\n",
       "15    This medical student showed little interest in...\n",
       "16    They were unable to effectively collaborate wi...\n",
       "17    This medical student demonstrated unprofession...\n",
       "18    This medical student demonstrated average comm...\n",
       "19    They were able to correctly diagnose the patie...\n",
       "Name: Comments, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments['Comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment analysis and question answering models\n",
    "sa_model = pipeline(\"sentiment-analysis\")\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: POSITIVE\n",
      "Answers: ['communication skills']\n"
     ]
    }
   ],
   "source": [
    "# Review to analyze\n",
    "review = \"This medical student has excellent communication skills, effectively conveying complex medical concepts\"\n",
    "\n",
    "# Perform sentiment analysis on the review\n",
    "sentiment = sa_model(review)[0]['label']\n",
    "\n",
    "# Extract key phrases from the review\n",
    "key_phrases = ['communication','concepts']\n",
    "\n",
    "# Generate questions based on the sentiment and key phrases\n",
    "if sentiment == 'POSITIVE':\n",
    "    questions = ['What made it good?']\n",
    "elif sentiment == 'NEGATIVE':\n",
    "    questions = ['Why was it bad?']\n",
    "else:\n",
    "    questions = ['What can you say about it?']\n",
    "\n",
    "# Use QA to answer the questions\n",
    "answers = []\n",
    "for question in questions:\n",
    "    answer = qa_model(question=question, context=review)\n",
    "    answers.append(answer['answer'])\n",
    "\n",
    "# Print the sentiment and answers\n",
    "print('Sentiment:', sentiment)\n",
    "print('Answers:', answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Load BioBERT model\n",
    "biobert = SentenceTransformer('gsarti/biobert-nli')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to LatentDirichletAllocation.fit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20328\\3192128576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Perform topic modeling using Latent Dirichlet Allocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Print the topics and the top words in each topic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    609\u001b[0m         \"\"\"\n\u001b[0;32m    610\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         X = self._check_non_neg_array(\n\u001b[0m\u001b[0;32m    612\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_n_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"LatentDirichletAllocation.fit\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36m_check_non_neg_array\u001b[1;34m(self, X, reset_n_features, whom)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \"\"\"\n\u001b[0;32m    540\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset_n_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m         \u001b[0mcheck_non_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\WongQiHuiYve\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to LatentDirichletAllocation.fit"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Convert the text data to sentence embeddings\n",
    "sentences = comments['Comments'].tolist()\n",
    "embeddings = biobert.encode(sentences)\n",
    "embeddings\n",
    "# scaler = StandardScaler()\n",
    "# data_scaled = scaler.fit_transform(embeddings)\n",
    "\n",
    "# # Perform topic modeling using Latent Dirichlet Allocation\n",
    "# lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "# lda.fit(embeddings)\n",
    "\n",
    "# # Print the topics and the top words in each topic\n",
    "# for idx, topic in enumerate(lda.components_):\n",
    "#     print('Topic %d:' % (idx))\n",
    "#     print(' '.join([biobert.decode([feature]) for feature in topic.argsort()[:-10 - 1:-1]]))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fine tuning an existing model, online dataset\n",
    "# bio gpt text classifier\n",
    "amazon=pd.read_csv('amazon_cells_labelled.csv')\n",
    "yelp=pd.read_csv('yelp_labelled.csv')\n",
    "imdb=pd.read_csv('imdb_labelled.csv')\n",
    "small_train_dataset=pd.concat([amazon,yelp,imdb])\n",
    "small_eval_dataset = comments[\"Comments\"].shuffle(seed=42).select(range(1000))\n",
    "small_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis, topic modelling, QA, keyword extraction/ner\n",
    "\n",
    "# self trained model, online dataset\n",
    "# fine tuning an existing model, self labelled dataset\n",
    "# self trained model, self labelled dataset\n",
    "\n",
    "# possible insights: if a certain programme has more negative comments, can reconsider the curriculum of the programe\n",
    "# other options for future consideration: amazon comprehend, google natural language api\n",
    "# limitation: word cannot be too long"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
